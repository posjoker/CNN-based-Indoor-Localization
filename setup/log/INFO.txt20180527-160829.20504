Log file created at: 2018/05/27 16:08:29
Running on machine: GLASSSIX-TITANX
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0527 16:08:29.784543 24728 caffe.cpp:220] Using GPUs 0, 1
I0527 16:08:29.802728 24728 caffe.cpp:225] GPU 0: GeForce GTX TITAN X
I0527 16:08:29.802728 24728 caffe.cpp:225] GPU 1: GeForce GTX TITAN X
I0527 16:08:30.048382 24728 solver.cpp:48] Initializing solver from parameters: 
test_iter: 7
test_interval: 125
base_lr: 0.01
display: 100
max_iter: 3000
lr_policy: "multistep"
gamma: 0.2
momentum: 0.9
weight_decay: 0.0005
snapshot: 500
snapshot_prefix: "D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20"
solver_mode: GPU
device_id: 0
net: "D:/Research/CNN-based-Indoor-Localization/model/resnet20.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
stepvalue: 1600
stepvalue: 2400
stepvalue: 2800
I0527 16:08:30.048382 24728 solver.cpp:92] Creating training net from net file: D:/Research/CNN-based-Indoor-Localization/model/resnet20.prototxt
I0527 16:08:30.049386 24728 net.cpp:344] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0527 16:08:30.050387 24728 net.cpp:344] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I0527 16:08:30.050387 24728 net.cpp:344] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I0527 16:08:30.052392 24728 net.cpp:76] Initializing net from parameters: 
name: "ResNet20"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "D:/Research/CNN-based-Indoor-Localization/lmdb/train_48"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "PReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "conv1_2"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
}
layer {
  name: "res1_3"
  type: "Eltwise"
  bottom: "conv1_1"
  bottom: "conv1_3"
  top: "res1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "res1_3"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "conv2_1"
  bottom: "conv2_3"
  top: "res2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_4"
  type: "PReLU"
  bottom: "conv2_4"
  top: "conv2_4"
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "conv2_4"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
}
layer {
  name: "res2_5"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_5"
  top: "res2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "res2_5"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "conv3_1"
  bottom: "conv3_3"
  top: "res3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "res3_5"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_5"
  top: "res3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_6"
  type: "Convolution"
  bottom: "res3_5"
  top: "conv3_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_6"
  type: "PReLU"
  bottom: "conv3_6"
  top: "conv3_6"
}
layer {
  name: "conv3_7"
  type: "Convolution"
  bottom: "conv3_6"
  top: "conv3_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_7"
  type: "PReLU"
  bottom: "conv3_7"
  top: "conv3_7"
}
layer {
  name: "res3_7"
  type: "Eltwise"
  bottom: "res3_5"
  bottom: "conv3_7"
  top: "res3_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_8"
  type: "Convolution"
  bottom: "res3_7"
  top: "conv3_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_8"
  type: "PReLU"
  bottom: "conv3_8"
  top: "conv3_8"
}
layer {
  name: "conv3_9"
  type: "Convolution"
  bottom: "conv3_8"
  top: "conv3_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_9"
  type: "PReLU"
  bottom: "conv3_9"
  top: "conv3_9"
}
layer {
  name: "res3_9"
  type: "Eltwise"
  bottom: "res3_7"
  bottom: "conv3_9"
  top: "res3_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "res3_9"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "res4_3"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_3"
  top: "res4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res4_3"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "softmax_loss"
}
I0527 16:08:30.059411 24728 layer_factory.hpp:77] Creating layer data
I0527 16:08:30.059411 24728 net.cpp:119] Creating Layer data
I0527 16:08:30.059411 24728 net.cpp:432] data -> data
I0527 16:08:30.059411 24728 net.cpp:432] data -> label
I0527 16:08:30.127611 23684 db_lmdb.cpp:40] Opened lmdb D:/Research/CNN-based-Indoor-Localization/lmdb/train_48
I0527 16:08:30.176723 24728 data_layer.cpp:41] output data size: 128,3,30,30
I0527 16:08:30.180732 24728 net.cpp:170] Setting up data
I0527 16:08:30.180732 24728 net.cpp:177] Top shape: 128 3 30 30 (345600)
I0527 16:08:30.181735 21860 blocking_queue.cpp:50] Waiting for data
I0527 16:08:30.182739 24728 net.cpp:177] Top shape: 128 (128)
I0527 16:08:30.183742 24728 net.cpp:185] Memory required for data: 1382912
I0527 16:08:30.184743 24728 layer_factory.hpp:77] Creating layer conv1_1
I0527 16:08:30.184743 24728 net.cpp:119] Creating Layer conv1_1
I0527 16:08:30.185746 24728 net.cpp:458] conv1_1 <- data
I0527 16:08:30.185746 24728 net.cpp:432] conv1_1 -> conv1_1
I0527 16:08:30.709147 24728 net.cpp:170] Setting up conv1_1
I0527 16:08:30.710150 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.711153 24728 net.cpp:185] Memory required for data: 3480064
I0527 16:08:30.712155 24728 layer_factory.hpp:77] Creating layer relu1_1
I0527 16:08:30.713157 24728 net.cpp:119] Creating Layer relu1_1
I0527 16:08:30.714161 24728 net.cpp:458] relu1_1 <- conv1_1
I0527 16:08:30.714161 24728 net.cpp:417] relu1_1 -> conv1_1 (in-place)
I0527 16:08:30.715163 24728 net.cpp:170] Setting up relu1_1
I0527 16:08:30.716166 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.716166 24728 net.cpp:185] Memory required for data: 5577216
I0527 16:08:30.717169 24728 layer_factory.hpp:77] Creating layer conv1_1_relu1_1_0_split
I0527 16:08:30.717169 24728 net.cpp:119] Creating Layer conv1_1_relu1_1_0_split
I0527 16:08:30.718171 24728 net.cpp:458] conv1_1_relu1_1_0_split <- conv1_1
I0527 16:08:30.718171 24728 net.cpp:432] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_0
I0527 16:08:30.718171 24728 net.cpp:432] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_1
I0527 16:08:30.718171 24728 net.cpp:170] Setting up conv1_1_relu1_1_0_split
I0527 16:08:30.718171 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.718171 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.719174 24728 net.cpp:185] Memory required for data: 9771520
I0527 16:08:30.719174 24728 layer_factory.hpp:77] Creating layer conv1_2
I0527 16:08:30.720176 24728 net.cpp:119] Creating Layer conv1_2
I0527 16:08:30.720176 24728 net.cpp:458] conv1_2 <- conv1_1_relu1_1_0_split_0
I0527 16:08:30.720176 24728 net.cpp:432] conv1_2 -> conv1_2
I0527 16:08:30.722182 24728 net.cpp:170] Setting up conv1_2
I0527 16:08:30.722182 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.722182 24728 net.cpp:185] Memory required for data: 11868672
I0527 16:08:30.722182 24728 layer_factory.hpp:77] Creating layer relu1_2
I0527 16:08:30.723184 24728 net.cpp:119] Creating Layer relu1_2
I0527 16:08:30.723184 24728 net.cpp:458] relu1_2 <- conv1_2
I0527 16:08:30.723184 24728 net.cpp:417] relu1_2 -> conv1_2 (in-place)
I0527 16:08:30.723184 24728 net.cpp:170] Setting up relu1_2
I0527 16:08:30.723184 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.723184 24728 net.cpp:185] Memory required for data: 13965824
I0527 16:08:30.723184 24728 layer_factory.hpp:77] Creating layer conv1_3
I0527 16:08:30.724187 24728 net.cpp:119] Creating Layer conv1_3
I0527 16:08:30.724187 24728 net.cpp:458] conv1_3 <- conv1_2
I0527 16:08:30.725190 24728 net.cpp:432] conv1_3 -> conv1_3
I0527 16:08:30.729202 24728 net.cpp:170] Setting up conv1_3
I0527 16:08:30.729202 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.730203 24728 net.cpp:185] Memory required for data: 16062976
I0527 16:08:30.730203 24728 layer_factory.hpp:77] Creating layer relu1_3
I0527 16:08:30.731205 24728 net.cpp:119] Creating Layer relu1_3
I0527 16:08:30.731205 24728 net.cpp:458] relu1_3 <- conv1_3
I0527 16:08:30.731205 24728 net.cpp:417] relu1_3 -> conv1_3 (in-place)
I0527 16:08:30.732208 24728 net.cpp:170] Setting up relu1_3
I0527 16:08:30.732208 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.733211 24728 net.cpp:185] Memory required for data: 18160128
I0527 16:08:30.734215 24728 layer_factory.hpp:77] Creating layer res1_3
I0527 16:08:30.734215 24728 net.cpp:119] Creating Layer res1_3
I0527 16:08:30.734215 24728 net.cpp:458] res1_3 <- conv1_1_relu1_1_0_split_1
I0527 16:08:30.734215 24728 net.cpp:458] res1_3 <- conv1_3
I0527 16:08:30.735216 24728 net.cpp:432] res1_3 -> res1_3
I0527 16:08:30.735216 24728 net.cpp:170] Setting up res1_3
I0527 16:08:30.735216 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:30.735216 24728 net.cpp:185] Memory required for data: 20257280
I0527 16:08:30.735216 24728 layer_factory.hpp:77] Creating layer conv2_1
I0527 16:08:30.735216 24728 net.cpp:119] Creating Layer conv2_1
I0527 16:08:30.736219 24728 net.cpp:458] conv2_1 <- res1_3
I0527 16:08:30.736219 24728 net.cpp:432] conv2_1 -> conv2_1
I0527 16:08:30.741233 24728 net.cpp:170] Setting up conv2_1
I0527 16:08:30.741233 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.741233 24728 net.cpp:185] Memory required for data: 21305856
I0527 16:08:30.741233 24728 layer_factory.hpp:77] Creating layer relu2_1
I0527 16:08:30.741233 24728 net.cpp:119] Creating Layer relu2_1
I0527 16:08:30.742235 24728 net.cpp:458] relu2_1 <- conv2_1
I0527 16:08:30.742235 24728 net.cpp:417] relu2_1 -> conv2_1 (in-place)
I0527 16:08:30.742235 24728 net.cpp:170] Setting up relu2_1
I0527 16:08:30.743238 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.744240 24728 net.cpp:185] Memory required for data: 22354432
I0527 16:08:30.745244 24728 layer_factory.hpp:77] Creating layer conv2_1_relu2_1_0_split
I0527 16:08:30.747248 24728 net.cpp:119] Creating Layer conv2_1_relu2_1_0_split
I0527 16:08:30.748251 24728 net.cpp:458] conv2_1_relu2_1_0_split <- conv2_1
I0527 16:08:30.749254 24728 net.cpp:432] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_0
I0527 16:08:30.750257 24728 net.cpp:432] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_1
I0527 16:08:30.750257 24728 net.cpp:170] Setting up conv2_1_relu2_1_0_split
I0527 16:08:30.752262 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.753264 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.754267 24728 net.cpp:185] Memory required for data: 24451584
I0527 16:08:30.755270 24728 layer_factory.hpp:77] Creating layer conv2_2
I0527 16:08:30.756273 24728 net.cpp:119] Creating Layer conv2_2
I0527 16:08:30.757275 24728 net.cpp:458] conv2_2 <- conv2_1_relu2_1_0_split_0
I0527 16:08:30.758277 24728 net.cpp:432] conv2_2 -> conv2_2
I0527 16:08:30.761286 24728 net.cpp:170] Setting up conv2_2
I0527 16:08:30.761286 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.761286 24728 net.cpp:185] Memory required for data: 25500160
I0527 16:08:30.761286 24728 layer_factory.hpp:77] Creating layer relu2_2
I0527 16:08:30.761286 24728 net.cpp:119] Creating Layer relu2_2
I0527 16:08:30.762293 24728 net.cpp:458] relu2_2 <- conv2_2
I0527 16:08:30.762293 24728 net.cpp:417] relu2_2 -> conv2_2 (in-place)
I0527 16:08:30.762293 24728 net.cpp:170] Setting up relu2_2
I0527 16:08:30.762293 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.762293 24728 net.cpp:185] Memory required for data: 26548736
I0527 16:08:30.762293 24728 layer_factory.hpp:77] Creating layer conv2_3
I0527 16:08:30.763291 24728 net.cpp:119] Creating Layer conv2_3
I0527 16:08:30.763291 24728 net.cpp:458] conv2_3 <- conv2_2
I0527 16:08:30.763291 24728 net.cpp:432] conv2_3 -> conv2_3
I0527 16:08:30.765296 24728 net.cpp:170] Setting up conv2_3
I0527 16:08:30.765296 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.765296 24728 net.cpp:185] Memory required for data: 27597312
I0527 16:08:30.766299 24728 layer_factory.hpp:77] Creating layer relu2_3
I0527 16:08:30.766299 24728 net.cpp:119] Creating Layer relu2_3
I0527 16:08:30.769307 24728 net.cpp:458] relu2_3 <- conv2_3
I0527 16:08:30.769307 24728 net.cpp:417] relu2_3 -> conv2_3 (in-place)
I0527 16:08:30.769307 24728 net.cpp:170] Setting up relu2_3
I0527 16:08:30.769307 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.769307 24728 net.cpp:185] Memory required for data: 28645888
I0527 16:08:30.769307 24728 layer_factory.hpp:77] Creating layer res2_3
I0527 16:08:30.771312 24728 net.cpp:119] Creating Layer res2_3
I0527 16:08:30.771312 24728 net.cpp:458] res2_3 <- conv2_1_relu2_1_0_split_1
I0527 16:08:30.771312 24728 net.cpp:458] res2_3 <- conv2_3
I0527 16:08:30.771312 24728 net.cpp:432] res2_3 -> res2_3
I0527 16:08:30.771312 24728 net.cpp:170] Setting up res2_3
I0527 16:08:30.772315 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.774320 24728 net.cpp:185] Memory required for data: 29694464
I0527 16:08:30.775323 24728 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0527 16:08:30.777328 24728 net.cpp:119] Creating Layer res2_3_res2_3_0_split
I0527 16:08:30.777328 24728 net.cpp:458] res2_3_res2_3_0_split <- res2_3
I0527 16:08:30.778331 24728 net.cpp:432] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0527 16:08:30.779335 24728 net.cpp:432] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0527 16:08:30.779335 24728 net.cpp:170] Setting up res2_3_res2_3_0_split
I0527 16:08:30.780336 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.780336 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.781338 24728 net.cpp:185] Memory required for data: 31791616
I0527 16:08:30.781338 24728 layer_factory.hpp:77] Creating layer conv2_4
I0527 16:08:30.781338 24728 net.cpp:119] Creating Layer conv2_4
I0527 16:08:30.781338 24728 net.cpp:458] conv2_4 <- res2_3_res2_3_0_split_0
I0527 16:08:30.782342 24728 net.cpp:432] conv2_4 -> conv2_4
I0527 16:08:30.784348 24728 net.cpp:170] Setting up conv2_4
I0527 16:08:30.784348 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.784348 24728 net.cpp:185] Memory required for data: 32840192
I0527 16:08:30.784348 24728 layer_factory.hpp:77] Creating layer relu2_4
I0527 16:08:30.785351 24728 net.cpp:119] Creating Layer relu2_4
I0527 16:08:30.785351 24728 net.cpp:458] relu2_4 <- conv2_4
I0527 16:08:30.785351 24728 net.cpp:417] relu2_4 -> conv2_4 (in-place)
I0527 16:08:30.785351 24728 net.cpp:170] Setting up relu2_4
I0527 16:08:30.785351 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.785351 24728 net.cpp:185] Memory required for data: 33888768
I0527 16:08:30.786353 24728 layer_factory.hpp:77] Creating layer conv2_5
I0527 16:08:30.786353 24728 net.cpp:119] Creating Layer conv2_5
I0527 16:08:30.786353 24728 net.cpp:458] conv2_5 <- conv2_4
I0527 16:08:30.786353 24728 net.cpp:432] conv2_5 -> conv2_5
I0527 16:08:30.788358 24728 net.cpp:170] Setting up conv2_5
I0527 16:08:30.788358 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.789361 24728 net.cpp:185] Memory required for data: 34937344
I0527 16:08:30.789361 24728 layer_factory.hpp:77] Creating layer relu2_5
I0527 16:08:30.789361 24728 net.cpp:119] Creating Layer relu2_5
I0527 16:08:30.789361 24728 net.cpp:458] relu2_5 <- conv2_5
I0527 16:08:30.789361 24728 net.cpp:417] relu2_5 -> conv2_5 (in-place)
I0527 16:08:30.789361 24728 net.cpp:170] Setting up relu2_5
I0527 16:08:30.789361 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.790364 24728 net.cpp:185] Memory required for data: 35985920
I0527 16:08:30.790364 24728 layer_factory.hpp:77] Creating layer res2_5
I0527 16:08:30.790364 24728 net.cpp:119] Creating Layer res2_5
I0527 16:08:30.790364 24728 net.cpp:458] res2_5 <- res2_3_res2_3_0_split_1
I0527 16:08:30.790364 24728 net.cpp:458] res2_5 <- conv2_5
I0527 16:08:30.790364 24728 net.cpp:432] res2_5 -> res2_5
I0527 16:08:30.790364 24728 net.cpp:170] Setting up res2_5
I0527 16:08:30.790364 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:30.791366 24728 net.cpp:185] Memory required for data: 37034496
I0527 16:08:30.791366 24728 layer_factory.hpp:77] Creating layer conv3_1
I0527 16:08:30.792368 24728 net.cpp:119] Creating Layer conv3_1
I0527 16:08:30.793370 24728 net.cpp:458] conv3_1 <- res2_5
I0527 16:08:30.795377 24728 net.cpp:432] conv3_1 -> conv3_1
I0527 16:08:30.800390 24728 net.cpp:170] Setting up conv3_1
I0527 16:08:30.800390 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.801393 24728 net.cpp:185] Memory required for data: 37558784
I0527 16:08:30.803397 24728 layer_factory.hpp:77] Creating layer relu3_1
I0527 16:08:30.804400 24728 net.cpp:119] Creating Layer relu3_1
I0527 16:08:30.804400 24728 net.cpp:458] relu3_1 <- conv3_1
I0527 16:08:30.805403 24728 net.cpp:417] relu3_1 -> conv3_1 (in-place)
I0527 16:08:30.806406 24728 net.cpp:170] Setting up relu3_1
I0527 16:08:30.806406 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.807410 24728 net.cpp:185] Memory required for data: 38083072
I0527 16:08:30.807410 24728 layer_factory.hpp:77] Creating layer conv3_1_relu3_1_0_split
I0527 16:08:30.807410 24728 net.cpp:119] Creating Layer conv3_1_relu3_1_0_split
I0527 16:08:30.807410 24728 net.cpp:458] conv3_1_relu3_1_0_split <- conv3_1
I0527 16:08:30.808411 24728 net.cpp:432] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_0
I0527 16:08:30.808411 24728 net.cpp:432] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_1
I0527 16:08:30.808411 24728 net.cpp:170] Setting up conv3_1_relu3_1_0_split
I0527 16:08:30.808411 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.808411 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.808411 24728 net.cpp:185] Memory required for data: 39131648
I0527 16:08:30.809414 24728 layer_factory.hpp:77] Creating layer conv3_2
I0527 16:08:30.809414 24728 net.cpp:119] Creating Layer conv3_2
I0527 16:08:30.809414 24728 net.cpp:458] conv3_2 <- conv3_1_relu3_1_0_split_0
I0527 16:08:30.809414 24728 net.cpp:432] conv3_2 -> conv3_2
I0527 16:08:30.812422 24728 net.cpp:170] Setting up conv3_2
I0527 16:08:30.812422 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.812422 24728 net.cpp:185] Memory required for data: 39655936
I0527 16:08:30.813426 24728 layer_factory.hpp:77] Creating layer relu3_2
I0527 16:08:30.813426 24728 net.cpp:119] Creating Layer relu3_2
I0527 16:08:30.813426 24728 net.cpp:458] relu3_2 <- conv3_2
I0527 16:08:30.813426 24728 net.cpp:417] relu3_2 -> conv3_2 (in-place)
I0527 16:08:30.813426 24728 net.cpp:170] Setting up relu3_2
I0527 16:08:30.813426 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.813426 24728 net.cpp:185] Memory required for data: 40180224
I0527 16:08:30.814427 24728 layer_factory.hpp:77] Creating layer conv3_3
I0527 16:08:30.814427 24728 net.cpp:119] Creating Layer conv3_3
I0527 16:08:30.814427 24728 net.cpp:458] conv3_3 <- conv3_2
I0527 16:08:30.814427 24728 net.cpp:432] conv3_3 -> conv3_3
I0527 16:08:30.817436 24728 net.cpp:170] Setting up conv3_3
I0527 16:08:30.817436 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.818439 24728 net.cpp:185] Memory required for data: 40704512
I0527 16:08:30.819442 24728 layer_factory.hpp:77] Creating layer relu3_3
I0527 16:08:30.819442 24728 net.cpp:119] Creating Layer relu3_3
I0527 16:08:30.819442 24728 net.cpp:458] relu3_3 <- conv3_3
I0527 16:08:30.819442 24728 net.cpp:417] relu3_3 -> conv3_3 (in-place)
I0527 16:08:30.819442 24728 net.cpp:170] Setting up relu3_3
I0527 16:08:30.820443 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.821446 24728 net.cpp:185] Memory required for data: 41228800
I0527 16:08:30.823451 24728 layer_factory.hpp:77] Creating layer res3_3
I0527 16:08:30.823451 24728 net.cpp:119] Creating Layer res3_3
I0527 16:08:30.824453 24728 net.cpp:458] res3_3 <- conv3_1_relu3_1_0_split_1
I0527 16:08:30.824453 24728 net.cpp:458] res3_3 <- conv3_3
I0527 16:08:30.825456 24728 net.cpp:432] res3_3 -> res3_3
I0527 16:08:30.825456 24728 net.cpp:170] Setting up res3_3
I0527 16:08:30.825456 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.825456 24728 net.cpp:185] Memory required for data: 41753088
I0527 16:08:30.826459 24728 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0527 16:08:30.826459 24728 net.cpp:119] Creating Layer res3_3_res3_3_0_split
I0527 16:08:30.826459 24728 net.cpp:458] res3_3_res3_3_0_split <- res3_3
I0527 16:08:30.826459 24728 net.cpp:432] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0527 16:08:30.827462 24728 net.cpp:432] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0527 16:08:30.828464 24728 net.cpp:170] Setting up res3_3_res3_3_0_split
I0527 16:08:30.829468 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.829468 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.829468 24728 net.cpp:185] Memory required for data: 42801664
I0527 16:08:30.829468 24728 layer_factory.hpp:77] Creating layer conv3_4
I0527 16:08:30.829468 24728 net.cpp:119] Creating Layer conv3_4
I0527 16:08:30.830471 24728 net.cpp:458] conv3_4 <- res3_3_res3_3_0_split_0
I0527 16:08:30.831473 24728 net.cpp:432] conv3_4 -> conv3_4
I0527 16:08:30.834481 24728 net.cpp:170] Setting up conv3_4
I0527 16:08:30.834481 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.836486 24728 net.cpp:185] Memory required for data: 43325952
I0527 16:08:30.837488 24728 layer_factory.hpp:77] Creating layer relu3_4
I0527 16:08:30.838491 24728 net.cpp:119] Creating Layer relu3_4
I0527 16:08:30.839494 24728 net.cpp:458] relu3_4 <- conv3_4
I0527 16:08:30.840497 24728 net.cpp:417] relu3_4 -> conv3_4 (in-place)
I0527 16:08:30.841500 24728 net.cpp:170] Setting up relu3_4
I0527 16:08:30.841500 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.842502 24728 net.cpp:185] Memory required for data: 43850240
I0527 16:08:30.842502 24728 layer_factory.hpp:77] Creating layer conv3_5
I0527 16:08:30.842502 24728 net.cpp:119] Creating Layer conv3_5
I0527 16:08:30.842502 24728 net.cpp:458] conv3_5 <- conv3_4
I0527 16:08:30.843505 24728 net.cpp:432] conv3_5 -> conv3_5
I0527 16:08:30.846513 24728 net.cpp:170] Setting up conv3_5
I0527 16:08:30.846513 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.846513 24728 net.cpp:185] Memory required for data: 44374528
I0527 16:08:30.846513 24728 layer_factory.hpp:77] Creating layer relu3_5
I0527 16:08:30.846513 24728 net.cpp:119] Creating Layer relu3_5
I0527 16:08:30.847515 24728 net.cpp:458] relu3_5 <- conv3_5
I0527 16:08:30.847515 24728 net.cpp:417] relu3_5 -> conv3_5 (in-place)
I0527 16:08:30.847515 24728 net.cpp:170] Setting up relu3_5
I0527 16:08:30.847515 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.847515 24728 net.cpp:185] Memory required for data: 44898816
I0527 16:08:30.847515 24728 layer_factory.hpp:77] Creating layer res3_5
I0527 16:08:30.848518 24728 net.cpp:119] Creating Layer res3_5
I0527 16:08:30.848518 24728 net.cpp:458] res3_5 <- res3_3_res3_3_0_split_1
I0527 16:08:30.848518 24728 net.cpp:458] res3_5 <- conv3_5
I0527 16:08:30.848518 24728 net.cpp:432] res3_5 -> res3_5
I0527 16:08:30.848518 24728 net.cpp:170] Setting up res3_5
I0527 16:08:30.848518 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.848518 24728 net.cpp:185] Memory required for data: 45423104
I0527 16:08:30.849520 24728 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0527 16:08:30.849520 24728 net.cpp:119] Creating Layer res3_5_res3_5_0_split
I0527 16:08:30.849520 24728 net.cpp:458] res3_5_res3_5_0_split <- res3_5
I0527 16:08:30.850523 24728 net.cpp:432] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0527 16:08:30.850523 24728 net.cpp:432] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0527 16:08:30.850523 24728 net.cpp:170] Setting up res3_5_res3_5_0_split
I0527 16:08:30.850523 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.850523 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.851526 24728 net.cpp:185] Memory required for data: 46471680
I0527 16:08:30.851526 24728 layer_factory.hpp:77] Creating layer conv3_6
I0527 16:08:30.851526 24728 net.cpp:119] Creating Layer conv3_6
I0527 16:08:30.851526 24728 net.cpp:458] conv3_6 <- res3_5_res3_5_0_split_0
I0527 16:08:30.851526 24728 net.cpp:432] conv3_6 -> conv3_6
I0527 16:08:30.854534 24728 net.cpp:170] Setting up conv3_6
I0527 16:08:30.854534 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.855536 24728 net.cpp:185] Memory required for data: 46995968
I0527 16:08:30.856539 24728 layer_factory.hpp:77] Creating layer relu3_6
I0527 16:08:30.857542 24728 net.cpp:119] Creating Layer relu3_6
I0527 16:08:30.858546 24728 net.cpp:458] relu3_6 <- conv3_6
I0527 16:08:30.861552 24728 net.cpp:417] relu3_6 -> conv3_6 (in-place)
I0527 16:08:30.861552 24728 net.cpp:170] Setting up relu3_6
I0527 16:08:30.861552 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.862563 24728 net.cpp:185] Memory required for data: 47520256
I0527 16:08:30.862563 24728 layer_factory.hpp:77] Creating layer conv3_7
I0527 16:08:30.862563 24728 net.cpp:119] Creating Layer conv3_7
I0527 16:08:30.862563 24728 net.cpp:458] conv3_7 <- conv3_6
I0527 16:08:30.862563 24728 net.cpp:432] conv3_7 -> conv3_7
I0527 16:08:30.865563 24728 net.cpp:170] Setting up conv3_7
I0527 16:08:30.865563 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.866566 24728 net.cpp:185] Memory required for data: 48044544
I0527 16:08:30.867568 24728 layer_factory.hpp:77] Creating layer relu3_7
I0527 16:08:30.868571 24728 net.cpp:119] Creating Layer relu3_7
I0527 16:08:30.869575 24728 net.cpp:458] relu3_7 <- conv3_7
I0527 16:08:30.870577 24728 net.cpp:417] relu3_7 -> conv3_7 (in-place)
I0527 16:08:30.870577 24728 net.cpp:170] Setting up relu3_7
I0527 16:08:30.871579 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.871579 24728 net.cpp:185] Memory required for data: 48568832
I0527 16:08:30.871579 24728 layer_factory.hpp:77] Creating layer res3_7
I0527 16:08:30.872582 24728 net.cpp:119] Creating Layer res3_7
I0527 16:08:30.872582 24728 net.cpp:458] res3_7 <- res3_5_res3_5_0_split_1
I0527 16:08:30.872582 24728 net.cpp:458] res3_7 <- conv3_7
I0527 16:08:30.872582 24728 net.cpp:432] res3_7 -> res3_7
I0527 16:08:30.872582 24728 net.cpp:170] Setting up res3_7
I0527 16:08:30.872582 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.872582 24728 net.cpp:185] Memory required for data: 49093120
I0527 16:08:30.873585 24728 layer_factory.hpp:77] Creating layer res3_7_res3_7_0_split
I0527 16:08:30.873585 24728 net.cpp:119] Creating Layer res3_7_res3_7_0_split
I0527 16:08:30.873585 24728 net.cpp:458] res3_7_res3_7_0_split <- res3_7
I0527 16:08:30.873585 24728 net.cpp:432] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_0
I0527 16:08:30.873585 24728 net.cpp:432] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_1
I0527 16:08:30.873585 24728 net.cpp:170] Setting up res3_7_res3_7_0_split
I0527 16:08:30.874586 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.874586 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.874586 24728 net.cpp:185] Memory required for data: 50141696
I0527 16:08:30.874586 24728 layer_factory.hpp:77] Creating layer conv3_8
I0527 16:08:30.874586 24728 net.cpp:119] Creating Layer conv3_8
I0527 16:08:30.874586 24728 net.cpp:458] conv3_8 <- res3_7_res3_7_0_split_0
I0527 16:08:30.874586 24728 net.cpp:432] conv3_8 -> conv3_8
I0527 16:08:30.878597 24728 net.cpp:170] Setting up conv3_8
I0527 16:08:30.878597 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.879601 24728 net.cpp:185] Memory required for data: 50665984
I0527 16:08:30.880604 24728 layer_factory.hpp:77] Creating layer relu3_8
I0527 16:08:30.881606 24728 net.cpp:119] Creating Layer relu3_8
I0527 16:08:30.881606 24728 net.cpp:458] relu3_8 <- conv3_8
I0527 16:08:30.882609 24728 net.cpp:417] relu3_8 -> conv3_8 (in-place)
I0527 16:08:30.883611 24728 net.cpp:170] Setting up relu3_8
I0527 16:08:30.884614 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.884614 24728 net.cpp:185] Memory required for data: 51190272
I0527 16:08:30.885617 24728 layer_factory.hpp:77] Creating layer conv3_9
I0527 16:08:30.885617 24728 net.cpp:119] Creating Layer conv3_9
I0527 16:08:30.885617 24728 net.cpp:458] conv3_9 <- conv3_8
I0527 16:08:30.885617 24728 net.cpp:432] conv3_9 -> conv3_9
I0527 16:08:30.891633 24728 net.cpp:170] Setting up conv3_9
I0527 16:08:30.891633 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.891633 24728 net.cpp:185] Memory required for data: 51714560
I0527 16:08:30.892634 24728 layer_factory.hpp:77] Creating layer relu3_9
I0527 16:08:30.893637 24728 net.cpp:119] Creating Layer relu3_9
I0527 16:08:30.895643 24728 net.cpp:458] relu3_9 <- conv3_9
I0527 16:08:30.896646 24728 net.cpp:417] relu3_9 -> conv3_9 (in-place)
I0527 16:08:30.898650 24728 net.cpp:170] Setting up relu3_9
I0527 16:08:30.898650 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.898650 24728 net.cpp:185] Memory required for data: 52238848
I0527 16:08:30.899654 24728 layer_factory.hpp:77] Creating layer res3_9
I0527 16:08:30.900656 24728 net.cpp:119] Creating Layer res3_9
I0527 16:08:30.900656 24728 net.cpp:458] res3_9 <- res3_7_res3_7_0_split_1
I0527 16:08:30.901659 24728 net.cpp:458] res3_9 <- conv3_9
I0527 16:08:30.902662 24728 net.cpp:432] res3_9 -> res3_9
I0527 16:08:30.902662 24728 net.cpp:170] Setting up res3_9
I0527 16:08:30.902662 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:30.902662 24728 net.cpp:185] Memory required for data: 52763136
I0527 16:08:30.903664 24728 layer_factory.hpp:77] Creating layer conv4_1
I0527 16:08:30.903664 24728 net.cpp:119] Creating Layer conv4_1
I0527 16:08:30.903664 24728 net.cpp:458] conv4_1 <- res3_9
I0527 16:08:30.903664 24728 net.cpp:432] conv4_1 -> conv4_1
I0527 16:08:30.906673 24728 net.cpp:170] Setting up conv4_1
I0527 16:08:30.906673 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.906673 24728 net.cpp:185] Memory required for data: 53025280
I0527 16:08:30.907675 24728 layer_factory.hpp:77] Creating layer relu4_1
I0527 16:08:30.907675 24728 net.cpp:119] Creating Layer relu4_1
I0527 16:08:30.907675 24728 net.cpp:458] relu4_1 <- conv4_1
I0527 16:08:30.907675 24728 net.cpp:417] relu4_1 -> conv4_1 (in-place)
I0527 16:08:30.907675 24728 net.cpp:170] Setting up relu4_1
I0527 16:08:30.907675 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.907675 24728 net.cpp:185] Memory required for data: 53287424
I0527 16:08:30.908679 24728 layer_factory.hpp:77] Creating layer conv4_1_relu4_1_0_split
I0527 16:08:30.908679 24728 net.cpp:119] Creating Layer conv4_1_relu4_1_0_split
I0527 16:08:30.908679 24728 net.cpp:458] conv4_1_relu4_1_0_split <- conv4_1
I0527 16:08:30.908679 24728 net.cpp:432] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_0
I0527 16:08:30.908679 24728 net.cpp:432] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_1
I0527 16:08:30.908679 24728 net.cpp:170] Setting up conv4_1_relu4_1_0_split
I0527 16:08:30.909680 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.909680 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.909680 24728 net.cpp:185] Memory required for data: 53811712
I0527 16:08:30.909680 24728 layer_factory.hpp:77] Creating layer conv4_2
I0527 16:08:30.909680 24728 net.cpp:119] Creating Layer conv4_2
I0527 16:08:30.909680 24728 net.cpp:458] conv4_2 <- conv4_1_relu4_1_0_split_0
I0527 16:08:30.910683 24728 net.cpp:432] conv4_2 -> conv4_2
I0527 16:08:30.913691 24728 net.cpp:170] Setting up conv4_2
I0527 16:08:30.913691 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.915696 24728 net.cpp:185] Memory required for data: 54073856
I0527 16:08:30.918705 24728 layer_factory.hpp:77] Creating layer relu4_2
I0527 16:08:30.919708 24728 net.cpp:119] Creating Layer relu4_2
I0527 16:08:30.919708 24728 net.cpp:458] relu4_2 <- conv4_2
I0527 16:08:30.919708 24728 net.cpp:417] relu4_2 -> conv4_2 (in-place)
I0527 16:08:30.919708 24728 net.cpp:170] Setting up relu4_2
I0527 16:08:30.919708 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.920711 24728 net.cpp:185] Memory required for data: 54336000
I0527 16:08:30.921712 24728 layer_factory.hpp:77] Creating layer conv4_3
I0527 16:08:30.921712 24728 net.cpp:119] Creating Layer conv4_3
I0527 16:08:30.921712 24728 net.cpp:458] conv4_3 <- conv4_2
I0527 16:08:30.921712 24728 net.cpp:432] conv4_3 -> conv4_3
I0527 16:08:30.926726 24728 net.cpp:170] Setting up conv4_3
I0527 16:08:30.926726 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.926726 24728 net.cpp:185] Memory required for data: 54598144
I0527 16:08:30.928731 24728 layer_factory.hpp:77] Creating layer relu4_3
I0527 16:08:30.929733 24728 net.cpp:119] Creating Layer relu4_3
I0527 16:08:30.930737 24728 net.cpp:458] relu4_3 <- conv4_3
I0527 16:08:30.931740 24728 net.cpp:417] relu4_3 -> conv4_3 (in-place)
I0527 16:08:30.931740 24728 net.cpp:170] Setting up relu4_3
I0527 16:08:30.932742 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.932742 24728 net.cpp:185] Memory required for data: 54860288
I0527 16:08:30.933745 24728 layer_factory.hpp:77] Creating layer res4_3
I0527 16:08:30.934747 24728 net.cpp:119] Creating Layer res4_3
I0527 16:08:30.935750 24728 net.cpp:458] res4_3 <- conv4_1_relu4_1_0_split_1
I0527 16:08:30.935750 24728 net.cpp:458] res4_3 <- conv4_3
I0527 16:08:30.935750 24728 net.cpp:432] res4_3 -> res4_3
I0527 16:08:30.936753 24728 net.cpp:170] Setting up res4_3
I0527 16:08:30.936753 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:30.936753 24728 net.cpp:185] Memory required for data: 55122432
I0527 16:08:30.936753 24728 layer_factory.hpp:77] Creating layer fc5
I0527 16:08:30.936753 24728 net.cpp:119] Creating Layer fc5
I0527 16:08:30.936753 24728 net.cpp:458] fc5 <- res4_3
I0527 16:08:30.937755 24728 net.cpp:432] fc5 -> fc5
I0527 16:08:30.937755 24728 net.cpp:170] Setting up fc5
I0527 16:08:30.937755 24728 net.cpp:177] Top shape: 128 48 (6144)
I0527 16:08:30.937755 24728 net.cpp:185] Memory required for data: 55147008
I0527 16:08:30.937755 24728 layer_factory.hpp:77] Creating layer softmax_loss
I0527 16:08:30.938758 24728 net.cpp:119] Creating Layer softmax_loss
I0527 16:08:30.939760 24728 net.cpp:458] softmax_loss <- fc5
I0527 16:08:30.940763 24728 net.cpp:458] softmax_loss <- label
I0527 16:08:30.941766 24728 net.cpp:432] softmax_loss -> softmax_loss
I0527 16:08:30.942768 24728 layer_factory.hpp:77] Creating layer softmax_loss
I0527 16:08:30.944773 24728 net.cpp:170] Setting up softmax_loss
I0527 16:08:30.944773 24728 net.cpp:177] Top shape: (1)
I0527 16:08:30.945777 24728 net.cpp:180]     with loss weight 1
I0527 16:08:30.945777 24728 net.cpp:185] Memory required for data: 55147012
I0527 16:08:30.945777 24728 net.cpp:246] softmax_loss needs backward computation.
I0527 16:08:30.946779 24728 net.cpp:246] fc5 needs backward computation.
I0527 16:08:30.946779 24728 net.cpp:246] res4_3 needs backward computation.
I0527 16:08:30.946779 24728 net.cpp:246] relu4_3 needs backward computation.
I0527 16:08:30.946779 24728 net.cpp:246] conv4_3 needs backward computation.
I0527 16:08:30.946779 24728 net.cpp:246] relu4_2 needs backward computation.
I0527 16:08:30.947782 24728 net.cpp:246] conv4_2 needs backward computation.
I0527 16:08:30.948784 24728 net.cpp:246] conv4_1_relu4_1_0_split needs backward computation.
I0527 16:08:30.948784 24728 net.cpp:246] relu4_1 needs backward computation.
I0527 16:08:30.949787 24728 net.cpp:246] conv4_1 needs backward computation.
I0527 16:08:30.949787 24728 net.cpp:246] res3_9 needs backward computation.
I0527 16:08:30.949787 24728 net.cpp:246] relu3_9 needs backward computation.
I0527 16:08:30.949787 24728 net.cpp:246] conv3_9 needs backward computation.
I0527 16:08:30.964915 24728 net.cpp:246] relu3_8 needs backward computation.
I0527 16:08:30.966881 24728 net.cpp:246] conv3_8 needs backward computation.
I0527 16:08:30.968885 24728 net.cpp:246] res3_7_res3_7_0_split needs backward computation.
I0527 16:08:30.969888 24728 net.cpp:246] res3_7 needs backward computation.
I0527 16:08:30.970890 24728 net.cpp:246] relu3_7 needs backward computation.
I0527 16:08:30.972896 24728 net.cpp:246] conv3_7 needs backward computation.
I0527 16:08:30.973898 24728 net.cpp:246] relu3_6 needs backward computation.
I0527 16:08:30.974901 24728 net.cpp:246] conv3_6 needs backward computation.
I0527 16:08:30.976907 24728 net.cpp:246] res3_5_res3_5_0_split needs backward computation.
I0527 16:08:30.978912 24728 net.cpp:246] res3_5 needs backward computation.
I0527 16:08:30.979914 24728 net.cpp:246] relu3_5 needs backward computation.
I0527 16:08:30.980916 24728 net.cpp:246] conv3_5 needs backward computation.
I0527 16:08:30.981920 24728 net.cpp:246] relu3_4 needs backward computation.
I0527 16:08:30.981920 24728 net.cpp:246] conv3_4 needs backward computation.
I0527 16:08:30.982923 24728 net.cpp:246] res3_3_res3_3_0_split needs backward computation.
I0527 16:08:30.983924 24728 net.cpp:246] res3_3 needs backward computation.
I0527 16:08:30.983924 24728 net.cpp:246] relu3_3 needs backward computation.
I0527 16:08:30.984927 24728 net.cpp:246] conv3_3 needs backward computation.
I0527 16:08:30.984927 24728 net.cpp:246] relu3_2 needs backward computation.
I0527 16:08:30.984927 24728 net.cpp:246] conv3_2 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] conv3_1_relu3_1_0_split needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] relu3_1 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] conv3_1 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] res2_5 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] relu2_5 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] conv2_5 needs backward computation.
I0527 16:08:30.985931 24728 net.cpp:246] relu2_4 needs backward computation.
I0527 16:08:30.986933 24728 net.cpp:246] conv2_4 needs backward computation.
I0527 16:08:30.986933 24728 net.cpp:246] res2_3_res2_3_0_split needs backward computation.
I0527 16:08:30.987936 24728 net.cpp:246] res2_3 needs backward computation.
I0527 16:08:30.988940 24728 net.cpp:246] relu2_3 needs backward computation.
I0527 16:08:30.989941 24728 net.cpp:246] conv2_3 needs backward computation.
I0527 16:08:30.990944 24728 net.cpp:246] relu2_2 needs backward computation.
I0527 16:08:30.991946 24728 net.cpp:246] conv2_2 needs backward computation.
I0527 16:08:30.992949 24728 net.cpp:246] conv2_1_relu2_1_0_split needs backward computation.
I0527 16:08:30.992949 24728 net.cpp:246] relu2_1 needs backward computation.
I0527 16:08:30.993952 24728 net.cpp:246] conv2_1 needs backward computation.
I0527 16:08:30.994956 24728 net.cpp:246] res1_3 needs backward computation.
I0527 16:08:30.995956 24728 net.cpp:246] relu1_3 needs backward computation.
I0527 16:08:30.995956 24728 net.cpp:246] conv1_3 needs backward computation.
I0527 16:08:30.995956 24728 net.cpp:246] relu1_2 needs backward computation.
I0527 16:08:30.995956 24728 net.cpp:246] conv1_2 needs backward computation.
I0527 16:08:30.995956 24728 net.cpp:246] conv1_1_relu1_1_0_split needs backward computation.
I0527 16:08:30.996968 24728 net.cpp:246] relu1_1 needs backward computation.
I0527 16:08:30.996968 24728 net.cpp:246] conv1_1 needs backward computation.
I0527 16:08:30.996968 24728 net.cpp:249] data does not need backward computation.
I0527 16:08:30.996968 24728 net.cpp:292] This network produces output softmax_loss
I0527 16:08:30.996968 24728 net.cpp:305] Network initialization done.
I0527 16:08:30.997962 24728 solver.cpp:184] Creating test net (#0) specified by net file: D:/Research/CNN-based-Indoor-Localization/model/resnet20.prototxt
I0527 16:08:30.997962 24728 net.cpp:344] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0527 16:08:30.998965 24728 net.cpp:76] Initializing net from parameters: 
name: "ResNet20"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "D:/Research/CNN-based-Indoor-Localization/lmdb/val_48"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "PReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "conv1_2"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
}
layer {
  name: "res1_3"
  type: "Eltwise"
  bottom: "conv1_1"
  bottom: "conv1_3"
  top: "res1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "res1_3"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "conv2_1"
  bottom: "conv2_3"
  top: "res2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_4"
  type: "PReLU"
  bottom: "conv2_4"
  top: "conv2_4"
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "conv2_4"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
}
layer {
  name: "res2_5"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_5"
  top: "res2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "res2_5"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "conv3_1"
  bottom: "conv3_3"
  top: "res3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "res3_5"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_5"
  top: "res3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_6"
  type: "Convolution"
  bottom: "res3_5"
  top: "conv3_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_6"
  type: "PReLU"
  bottom: "conv3_6"
  top: "conv3_6"
}
layer {
  name: "conv3_7"
  type: "Convolution"
  bottom: "conv3_6"
  top: "conv3_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_7"
  type: "PReLU"
  bottom: "conv3_7"
  top: "conv3_7"
}
layer {
  name: "res3_7"
  type: "Eltwise"
  bottom: "res3_5"
  bottom: "conv3_7"
  top: "res3_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_8"
  type: "Convolution"
  bottom: "res3_7"
  top: "conv3_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_8"
  type: "PReLU"
  bottom: "conv3_8"
  top: "conv3_8"
}
layer {
  name: "conv3_9"
  type: "Convolution"
  bottom: "conv3_8"
  top: "conv3_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_9"
  type: "PReLU"
  bottom: "conv3_9"
  top: "conv3_9"
}
layer {
  name: "res3_9"
  type: "Eltwise"
  bottom: "res3_7"
  bottom: "conv3_9"
  top: "res3_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "res3_9"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "res4_3"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_3"
  top: "res4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res4_3"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "softmax_loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0527 16:08:31.003978 24728 layer_factory.hpp:77] Creating layer data
I0527 16:08:31.004981 24728 net.cpp:119] Creating Layer data
I0527 16:08:31.005985 24728 net.cpp:432] data -> data
I0527 16:08:31.006986 24728 net.cpp:432] data -> label
I0527 16:08:31.039072 19532 db_lmdb.cpp:40] Opened lmdb D:/Research/CNN-based-Indoor-Localization/lmdb/val_48
I0527 16:08:31.040074 24728 data_layer.cpp:41] output data size: 128,3,30,30
I0527 16:08:31.044085 24728 net.cpp:170] Setting up data
I0527 16:08:31.044085 24728 net.cpp:177] Top shape: 128 3 30 30 (345600)
I0527 16:08:31.044085 24728 net.cpp:177] Top shape: 128 (128)
I0527 16:08:31.045089 24728 net.cpp:185] Memory required for data: 1382912
I0527 16:08:31.045089 24728 layer_factory.hpp:77] Creating layer label_data_1_split
I0527 16:08:31.045089 24728 net.cpp:119] Creating Layer label_data_1_split
I0527 16:08:31.045089 24728 net.cpp:458] label_data_1_split <- label
I0527 16:08:31.046092 24728 net.cpp:432] label_data_1_split -> label_data_1_split_0
I0527 16:08:31.046092 24728 net.cpp:432] label_data_1_split -> label_data_1_split_1
I0527 16:08:31.046092 24728 net.cpp:432] label_data_1_split -> label_data_1_split_2
I0527 16:08:31.046092 24728 net.cpp:170] Setting up label_data_1_split
I0527 16:08:31.046092 24728 net.cpp:177] Top shape: 128 (128)
I0527 16:08:31.046092 24728 net.cpp:177] Top shape: 128 (128)
I0527 16:08:31.046092 24728 net.cpp:177] Top shape: 128 (128)
I0527 16:08:31.047093 24728 net.cpp:185] Memory required for data: 1384448
I0527 16:08:31.047093 24728 layer_factory.hpp:77] Creating layer conv1_1
I0527 16:08:31.047093 24728 net.cpp:119] Creating Layer conv1_1
I0527 16:08:31.047093 24728 net.cpp:458] conv1_1 <- data
I0527 16:08:31.047093 24728 net.cpp:432] conv1_1 -> conv1_1
I0527 16:08:31.049098 24728 net.cpp:170] Setting up conv1_1
I0527 16:08:31.049098 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.049098 24728 net.cpp:185] Memory required for data: 3481600
I0527 16:08:31.049098 24728 layer_factory.hpp:77] Creating layer relu1_1
I0527 16:08:31.050101 24728 net.cpp:119] Creating Layer relu1_1
I0527 16:08:31.050101 24728 net.cpp:458] relu1_1 <- conv1_1
I0527 16:08:31.050101 24728 net.cpp:417] relu1_1 -> conv1_1 (in-place)
I0527 16:08:31.050101 24728 net.cpp:170] Setting up relu1_1
I0527 16:08:31.050101 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.051105 24728 net.cpp:185] Memory required for data: 5578752
I0527 16:08:31.051105 24728 layer_factory.hpp:77] Creating layer conv1_1_relu1_1_0_split
I0527 16:08:31.051105 24728 net.cpp:119] Creating Layer conv1_1_relu1_1_0_split
I0527 16:08:31.051105 24728 net.cpp:458] conv1_1_relu1_1_0_split <- conv1_1
I0527 16:08:31.051105 24728 net.cpp:432] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_0
I0527 16:08:31.051105 24728 net.cpp:432] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_1
I0527 16:08:31.052108 24728 net.cpp:170] Setting up conv1_1_relu1_1_0_split
I0527 16:08:31.052108 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.052108 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.052108 24728 net.cpp:185] Memory required for data: 9773056
I0527 16:08:31.052108 24728 layer_factory.hpp:77] Creating layer conv1_2
I0527 16:08:31.052108 24728 net.cpp:119] Creating Layer conv1_2
I0527 16:08:31.052108 24728 net.cpp:458] conv1_2 <- conv1_1_relu1_1_0_split_0
I0527 16:08:31.053109 24728 net.cpp:432] conv1_2 -> conv1_2
I0527 16:08:31.055114 24728 net.cpp:170] Setting up conv1_2
I0527 16:08:31.056116 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.057121 24728 net.cpp:185] Memory required for data: 11870208
I0527 16:08:31.058122 24728 layer_factory.hpp:77] Creating layer relu1_2
I0527 16:08:31.060128 24728 net.cpp:119] Creating Layer relu1_2
I0527 16:08:31.061131 24728 net.cpp:458] relu1_2 <- conv1_2
I0527 16:08:31.061131 24728 net.cpp:417] relu1_2 -> conv1_2 (in-place)
I0527 16:08:31.062134 24728 net.cpp:170] Setting up relu1_2
I0527 16:08:31.063148 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.063148 24728 net.cpp:185] Memory required for data: 13967360
I0527 16:08:31.065140 24728 layer_factory.hpp:77] Creating layer conv1_3
I0527 16:08:31.066143 24728 net.cpp:119] Creating Layer conv1_3
I0527 16:08:31.067147 24728 net.cpp:458] conv1_3 <- conv1_2
I0527 16:08:31.068148 24728 net.cpp:432] conv1_3 -> conv1_3
I0527 16:08:31.074167 24728 net.cpp:170] Setting up conv1_3
I0527 16:08:31.074167 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.074167 24728 net.cpp:185] Memory required for data: 16064512
I0527 16:08:31.074167 24728 layer_factory.hpp:77] Creating layer relu1_3
I0527 16:08:31.074167 24728 net.cpp:119] Creating Layer relu1_3
I0527 16:08:31.075168 24728 net.cpp:458] relu1_3 <- conv1_3
I0527 16:08:31.075168 24728 net.cpp:417] relu1_3 -> conv1_3 (in-place)
I0527 16:08:31.075168 24728 net.cpp:170] Setting up relu1_3
I0527 16:08:31.075168 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.075168 24728 net.cpp:185] Memory required for data: 18161664
I0527 16:08:31.076171 24728 layer_factory.hpp:77] Creating layer res1_3
I0527 16:08:31.076171 24728 net.cpp:119] Creating Layer res1_3
I0527 16:08:31.077173 24728 net.cpp:458] res1_3 <- conv1_1_relu1_1_0_split_1
I0527 16:08:31.077173 24728 net.cpp:458] res1_3 <- conv1_3
I0527 16:08:31.077173 24728 net.cpp:432] res1_3 -> res1_3
I0527 16:08:31.077173 24728 net.cpp:170] Setting up res1_3
I0527 16:08:31.077173 24728 net.cpp:177] Top shape: 128 16 16 16 (524288)
I0527 16:08:31.077173 24728 net.cpp:185] Memory required for data: 20258816
I0527 16:08:31.078176 24728 layer_factory.hpp:77] Creating layer conv2_1
I0527 16:08:31.078176 24728 net.cpp:119] Creating Layer conv2_1
I0527 16:08:31.078176 24728 net.cpp:458] conv2_1 <- res1_3
I0527 16:08:31.078176 24728 net.cpp:432] conv2_1 -> conv2_1
I0527 16:08:31.080180 24728 net.cpp:170] Setting up conv2_1
I0527 16:08:31.080180 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.081184 24728 net.cpp:185] Memory required for data: 21307392
I0527 16:08:31.082186 24728 layer_factory.hpp:77] Creating layer relu2_1
I0527 16:08:31.083189 24728 net.cpp:119] Creating Layer relu2_1
I0527 16:08:31.084192 24728 net.cpp:458] relu2_1 <- conv2_1
I0527 16:08:31.085194 24728 net.cpp:417] relu2_1 -> conv2_1 (in-place)
I0527 16:08:31.086196 24728 net.cpp:170] Setting up relu2_1
I0527 16:08:31.087200 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.088202 24728 net.cpp:185] Memory required for data: 22355968
I0527 16:08:31.088202 24728 layer_factory.hpp:77] Creating layer conv2_1_relu2_1_0_split
I0527 16:08:31.088202 24728 net.cpp:119] Creating Layer conv2_1_relu2_1_0_split
I0527 16:08:31.089205 24728 net.cpp:458] conv2_1_relu2_1_0_split <- conv2_1
I0527 16:08:31.089205 24728 net.cpp:432] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_0
I0527 16:08:31.089205 24728 net.cpp:432] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_1
I0527 16:08:31.089205 24728 net.cpp:170] Setting up conv2_1_relu2_1_0_split
I0527 16:08:31.089205 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.089205 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.090209 24728 net.cpp:185] Memory required for data: 24453120
I0527 16:08:31.090209 24728 layer_factory.hpp:77] Creating layer conv2_2
I0527 16:08:31.090209 24728 net.cpp:119] Creating Layer conv2_2
I0527 16:08:31.090209 24728 net.cpp:458] conv2_2 <- conv2_1_relu2_1_0_split_0
I0527 16:08:31.090209 24728 net.cpp:432] conv2_2 -> conv2_2
I0527 16:08:31.093215 24728 net.cpp:170] Setting up conv2_2
I0527 16:08:31.093215 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.093215 24728 net.cpp:185] Memory required for data: 25501696
I0527 16:08:31.093215 24728 layer_factory.hpp:77] Creating layer relu2_2
I0527 16:08:31.093215 24728 net.cpp:119] Creating Layer relu2_2
I0527 16:08:31.093215 24728 net.cpp:458] relu2_2 <- conv2_2
I0527 16:08:31.094218 24728 net.cpp:417] relu2_2 -> conv2_2 (in-place)
I0527 16:08:31.094218 24728 net.cpp:170] Setting up relu2_2
I0527 16:08:31.094218 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.094218 24728 net.cpp:185] Memory required for data: 26550272
I0527 16:08:31.094218 24728 layer_factory.hpp:77] Creating layer conv2_3
I0527 16:08:31.094218 24728 net.cpp:119] Creating Layer conv2_3
I0527 16:08:31.094218 24728 net.cpp:458] conv2_3 <- conv2_2
I0527 16:08:31.095221 24728 net.cpp:432] conv2_3 -> conv2_3
I0527 16:08:31.101236 24728 net.cpp:170] Setting up conv2_3
I0527 16:08:31.101236 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.101236 24728 net.cpp:185] Memory required for data: 27598848
I0527 16:08:31.103242 24728 layer_factory.hpp:77] Creating layer relu2_3
I0527 16:08:31.104244 24728 net.cpp:119] Creating Layer relu2_3
I0527 16:08:31.105248 24728 net.cpp:458] relu2_3 <- conv2_3
I0527 16:08:31.106251 24728 net.cpp:417] relu2_3 -> conv2_3 (in-place)
I0527 16:08:31.107254 24728 net.cpp:170] Setting up relu2_3
I0527 16:08:31.108256 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.108256 24728 net.cpp:185] Memory required for data: 28647424
I0527 16:08:31.109257 24728 layer_factory.hpp:77] Creating layer res2_3
I0527 16:08:31.110261 24728 net.cpp:119] Creating Layer res2_3
I0527 16:08:31.110261 24728 net.cpp:458] res2_3 <- conv2_1_relu2_1_0_split_1
I0527 16:08:31.110261 24728 net.cpp:458] res2_3 <- conv2_3
I0527 16:08:31.111264 24728 net.cpp:432] res2_3 -> res2_3
I0527 16:08:31.111264 24728 net.cpp:170] Setting up res2_3
I0527 16:08:31.111264 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.111264 24728 net.cpp:185] Memory required for data: 29696000
I0527 16:08:31.111264 24728 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0527 16:08:31.111264 24728 net.cpp:119] Creating Layer res2_3_res2_3_0_split
I0527 16:08:31.112267 24728 net.cpp:458] res2_3_res2_3_0_split <- res2_3
I0527 16:08:31.112267 24728 net.cpp:432] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0527 16:08:31.112267 24728 net.cpp:432] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0527 16:08:31.112267 24728 net.cpp:170] Setting up res2_3_res2_3_0_split
I0527 16:08:31.112267 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.112267 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.112267 24728 net.cpp:185] Memory required for data: 31793152
I0527 16:08:31.113270 24728 layer_factory.hpp:77] Creating layer conv2_4
I0527 16:08:31.113270 24728 net.cpp:119] Creating Layer conv2_4
I0527 16:08:31.113270 24728 net.cpp:458] conv2_4 <- res2_3_res2_3_0_split_0
I0527 16:08:31.114271 24728 net.cpp:432] conv2_4 -> conv2_4
I0527 16:08:31.116277 24728 net.cpp:170] Setting up conv2_4
I0527 16:08:31.116277 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.117280 24728 net.cpp:185] Memory required for data: 32841728
I0527 16:08:31.118283 24728 layer_factory.hpp:77] Creating layer relu2_4
I0527 16:08:31.119285 24728 net.cpp:119] Creating Layer relu2_4
I0527 16:08:31.119285 24728 net.cpp:458] relu2_4 <- conv2_4
I0527 16:08:31.120288 24728 net.cpp:417] relu2_4 -> conv2_4 (in-place)
I0527 16:08:31.121289 24728 net.cpp:170] Setting up relu2_4
I0527 16:08:31.121289 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.122293 24728 net.cpp:185] Memory required for data: 33890304
I0527 16:08:31.123296 24728 layer_factory.hpp:77] Creating layer conv2_5
I0527 16:08:31.124300 24728 net.cpp:119] Creating Layer conv2_5
I0527 16:08:31.124300 24728 net.cpp:458] conv2_5 <- conv2_4
I0527 16:08:31.124300 24728 net.cpp:432] conv2_5 -> conv2_5
I0527 16:08:31.129312 24728 net.cpp:170] Setting up conv2_5
I0527 16:08:31.130314 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.131317 24728 net.cpp:185] Memory required for data: 34938880
I0527 16:08:31.131317 24728 layer_factory.hpp:77] Creating layer relu2_5
I0527 16:08:31.132319 24728 net.cpp:119] Creating Layer relu2_5
I0527 16:08:31.133322 24728 net.cpp:458] relu2_5 <- conv2_5
I0527 16:08:31.134325 24728 net.cpp:417] relu2_5 -> conv2_5 (in-place)
I0527 16:08:31.135327 24728 net.cpp:170] Setting up relu2_5
I0527 16:08:31.135327 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.136329 24728 net.cpp:185] Memory required for data: 35987456
I0527 16:08:31.136329 24728 layer_factory.hpp:77] Creating layer res2_5
I0527 16:08:31.137332 24728 net.cpp:119] Creating Layer res2_5
I0527 16:08:31.137332 24728 net.cpp:458] res2_5 <- res2_3_res2_3_0_split_1
I0527 16:08:31.137332 24728 net.cpp:458] res2_5 <- conv2_5
I0527 16:08:31.137332 24728 net.cpp:432] res2_5 -> res2_5
I0527 16:08:31.137332 24728 net.cpp:170] Setting up res2_5
I0527 16:08:31.138336 24728 net.cpp:177] Top shape: 128 32 8 8 (262144)
I0527 16:08:31.138336 24728 net.cpp:185] Memory required for data: 37036032
I0527 16:08:31.138336 24728 layer_factory.hpp:77] Creating layer conv3_1
I0527 16:08:31.138336 24728 net.cpp:119] Creating Layer conv3_1
I0527 16:08:31.138336 24728 net.cpp:458] conv3_1 <- res2_5
I0527 16:08:31.138336 24728 net.cpp:432] conv3_1 -> conv3_1
I0527 16:08:31.141343 24728 net.cpp:170] Setting up conv3_1
I0527 16:08:31.141343 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.141343 24728 net.cpp:185] Memory required for data: 37560320
I0527 16:08:31.141343 24728 layer_factory.hpp:77] Creating layer relu3_1
I0527 16:08:31.141343 24728 net.cpp:119] Creating Layer relu3_1
I0527 16:08:31.141343 24728 net.cpp:458] relu3_1 <- conv3_1
I0527 16:08:31.142346 24728 net.cpp:417] relu3_1 -> conv3_1 (in-place)
I0527 16:08:31.142346 24728 net.cpp:170] Setting up relu3_1
I0527 16:08:31.142346 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.142346 24728 net.cpp:185] Memory required for data: 38084608
I0527 16:08:31.142346 24728 layer_factory.hpp:77] Creating layer conv3_1_relu3_1_0_split
I0527 16:08:31.142346 24728 net.cpp:119] Creating Layer conv3_1_relu3_1_0_split
I0527 16:08:31.143349 24728 net.cpp:458] conv3_1_relu3_1_0_split <- conv3_1
I0527 16:08:31.143349 24728 net.cpp:432] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_0
I0527 16:08:31.143349 24728 net.cpp:432] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_1
I0527 16:08:31.143349 24728 net.cpp:170] Setting up conv3_1_relu3_1_0_split
I0527 16:08:31.143349 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.144351 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.144351 24728 net.cpp:185] Memory required for data: 39133184
I0527 16:08:31.144351 24728 layer_factory.hpp:77] Creating layer conv3_2
I0527 16:08:31.144351 24728 net.cpp:119] Creating Layer conv3_2
I0527 16:08:31.144351 24728 net.cpp:458] conv3_2 <- conv3_1_relu3_1_0_split_0
I0527 16:08:31.144351 24728 net.cpp:432] conv3_2 -> conv3_2
I0527 16:08:31.147361 24728 net.cpp:170] Setting up conv3_2
I0527 16:08:31.147361 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.148362 24728 net.cpp:185] Memory required for data: 39657472
I0527 16:08:31.149365 24728 layer_factory.hpp:77] Creating layer relu3_2
I0527 16:08:31.151371 24728 net.cpp:119] Creating Layer relu3_2
I0527 16:08:31.151371 24728 net.cpp:458] relu3_2 <- conv3_2
I0527 16:08:31.152372 24728 net.cpp:417] relu3_2 -> conv3_2 (in-place)
I0527 16:08:31.153375 24728 net.cpp:170] Setting up relu3_2
I0527 16:08:31.153375 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.153375 24728 net.cpp:185] Memory required for data: 40181760
I0527 16:08:31.153375 24728 layer_factory.hpp:77] Creating layer conv3_3
I0527 16:08:31.154378 24728 net.cpp:119] Creating Layer conv3_3
I0527 16:08:31.154378 24728 net.cpp:458] conv3_3 <- conv3_2
I0527 16:08:31.154378 24728 net.cpp:432] conv3_3 -> conv3_3
I0527 16:08:31.158390 24728 net.cpp:170] Setting up conv3_3
I0527 16:08:31.159391 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.159391 24728 net.cpp:185] Memory required for data: 40706048
I0527 16:08:31.159391 24728 layer_factory.hpp:77] Creating layer relu3_3
I0527 16:08:31.160394 24728 net.cpp:119] Creating Layer relu3_3
I0527 16:08:31.160394 24728 net.cpp:458] relu3_3 <- conv3_3
I0527 16:08:31.160394 24728 net.cpp:417] relu3_3 -> conv3_3 (in-place)
I0527 16:08:31.160394 24728 net.cpp:170] Setting up relu3_3
I0527 16:08:31.160394 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.160394 24728 net.cpp:185] Memory required for data: 41230336
I0527 16:08:31.162400 24728 layer_factory.hpp:77] Creating layer res3_3
I0527 16:08:31.162400 24728 net.cpp:119] Creating Layer res3_3
I0527 16:08:31.162400 24728 net.cpp:458] res3_3 <- conv3_1_relu3_1_0_split_1
I0527 16:08:31.162400 24728 net.cpp:458] res3_3 <- conv3_3
I0527 16:08:31.162400 24728 net.cpp:432] res3_3 -> res3_3
I0527 16:08:31.162400 24728 net.cpp:170] Setting up res3_3
I0527 16:08:31.163403 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.163403 24728 net.cpp:185] Memory required for data: 41754624
I0527 16:08:31.163403 24728 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0527 16:08:31.163403 24728 net.cpp:119] Creating Layer res3_3_res3_3_0_split
I0527 16:08:31.163403 24728 net.cpp:458] res3_3_res3_3_0_split <- res3_3
I0527 16:08:31.163403 24728 net.cpp:432] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0527 16:08:31.164405 24728 net.cpp:432] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0527 16:08:31.164405 24728 net.cpp:170] Setting up res3_3_res3_3_0_split
I0527 16:08:31.164405 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.164405 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.164405 24728 net.cpp:185] Memory required for data: 42803200
I0527 16:08:31.164405 24728 layer_factory.hpp:77] Creating layer conv3_4
I0527 16:08:31.165408 24728 net.cpp:119] Creating Layer conv3_4
I0527 16:08:31.166411 24728 net.cpp:458] conv3_4 <- res3_3_res3_3_0_split_0
I0527 16:08:31.168416 24728 net.cpp:432] conv3_4 -> conv3_4
I0527 16:08:31.172426 24728 net.cpp:170] Setting up conv3_4
I0527 16:08:31.173429 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.173429 24728 net.cpp:185] Memory required for data: 43327488
I0527 16:08:31.173429 24728 layer_factory.hpp:77] Creating layer relu3_4
I0527 16:08:31.173429 24728 net.cpp:119] Creating Layer relu3_4
I0527 16:08:31.173429 24728 net.cpp:458] relu3_4 <- conv3_4
I0527 16:08:31.174432 24728 net.cpp:417] relu3_4 -> conv3_4 (in-place)
I0527 16:08:31.174432 24728 net.cpp:170] Setting up relu3_4
I0527 16:08:31.174432 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.174432 24728 net.cpp:185] Memory required for data: 43851776
I0527 16:08:31.174432 24728 layer_factory.hpp:77] Creating layer conv3_5
I0527 16:08:31.174432 24728 net.cpp:119] Creating Layer conv3_5
I0527 16:08:31.175434 24728 net.cpp:458] conv3_5 <- conv3_4
I0527 16:08:31.175434 24728 net.cpp:432] conv3_5 -> conv3_5
I0527 16:08:31.179445 24728 net.cpp:170] Setting up conv3_5
I0527 16:08:31.179445 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.180447 24728 net.cpp:185] Memory required for data: 44376064
I0527 16:08:31.181450 24728 layer_factory.hpp:77] Creating layer relu3_5
I0527 16:08:31.181450 24728 net.cpp:119] Creating Layer relu3_5
I0527 16:08:31.182453 24728 net.cpp:458] relu3_5 <- conv3_5
I0527 16:08:31.182453 24728 net.cpp:417] relu3_5 -> conv3_5 (in-place)
I0527 16:08:31.183455 24728 net.cpp:170] Setting up relu3_5
I0527 16:08:31.183455 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.183455 24728 net.cpp:185] Memory required for data: 44900352
I0527 16:08:31.184458 24728 layer_factory.hpp:77] Creating layer res3_5
I0527 16:08:31.184458 24728 net.cpp:119] Creating Layer res3_5
I0527 16:08:31.184458 24728 net.cpp:458] res3_5 <- res3_3_res3_3_0_split_1
I0527 16:08:31.184458 24728 net.cpp:458] res3_5 <- conv3_5
I0527 16:08:31.184458 24728 net.cpp:432] res3_5 -> res3_5
I0527 16:08:31.185461 24728 net.cpp:170] Setting up res3_5
I0527 16:08:31.185461 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.185461 24728 net.cpp:185] Memory required for data: 45424640
I0527 16:08:31.185461 24728 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0527 16:08:31.185461 24728 net.cpp:119] Creating Layer res3_5_res3_5_0_split
I0527 16:08:31.185461 24728 net.cpp:458] res3_5_res3_5_0_split <- res3_5
I0527 16:08:31.186465 24728 net.cpp:432] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0527 16:08:31.186465 24728 net.cpp:432] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0527 16:08:31.186465 24728 net.cpp:170] Setting up res3_5_res3_5_0_split
I0527 16:08:31.186465 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.186465 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.186465 24728 net.cpp:185] Memory required for data: 46473216
I0527 16:08:31.187466 24728 layer_factory.hpp:77] Creating layer conv3_6
I0527 16:08:31.190475 24728 net.cpp:119] Creating Layer conv3_6
I0527 16:08:31.190475 24728 net.cpp:458] conv3_6 <- res3_5_res3_5_0_split_0
I0527 16:08:31.191478 24728 net.cpp:432] conv3_6 -> conv3_6
I0527 16:08:31.196491 24728 net.cpp:170] Setting up conv3_6
I0527 16:08:31.196491 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.197494 24728 net.cpp:185] Memory required for data: 46997504
I0527 16:08:31.197494 24728 layer_factory.hpp:77] Creating layer relu3_6
I0527 16:08:31.198509 24728 net.cpp:119] Creating Layer relu3_6
I0527 16:08:31.199497 24728 net.cpp:458] relu3_6 <- conv3_6
I0527 16:08:31.199497 24728 net.cpp:417] relu3_6 -> conv3_6 (in-place)
I0527 16:08:31.200511 24728 net.cpp:170] Setting up relu3_6
I0527 16:08:31.200511 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.200511 24728 net.cpp:185] Memory required for data: 47521792
I0527 16:08:31.200511 24728 layer_factory.hpp:77] Creating layer conv3_7
I0527 16:08:31.201503 24728 net.cpp:119] Creating Layer conv3_7
I0527 16:08:31.201503 24728 net.cpp:458] conv3_7 <- conv3_6
I0527 16:08:31.201503 24728 net.cpp:432] conv3_7 -> conv3_7
I0527 16:08:31.204511 24728 net.cpp:170] Setting up conv3_7
I0527 16:08:31.204511 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.204511 24728 net.cpp:185] Memory required for data: 48046080
I0527 16:08:31.204511 24728 layer_factory.hpp:77] Creating layer relu3_7
I0527 16:08:31.205515 24728 net.cpp:119] Creating Layer relu3_7
I0527 16:08:31.205515 24728 net.cpp:458] relu3_7 <- conv3_7
I0527 16:08:31.205515 24728 net.cpp:417] relu3_7 -> conv3_7 (in-place)
I0527 16:08:31.206518 24728 net.cpp:170] Setting up relu3_7
I0527 16:08:31.206518 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.206518 24728 net.cpp:185] Memory required for data: 48570368
I0527 16:08:31.206518 24728 layer_factory.hpp:77] Creating layer res3_7
I0527 16:08:31.206518 24728 net.cpp:119] Creating Layer res3_7
I0527 16:08:31.207521 24728 net.cpp:458] res3_7 <- res3_5_res3_5_0_split_1
I0527 16:08:31.207521 24728 net.cpp:458] res3_7 <- conv3_7
I0527 16:08:31.207521 24728 net.cpp:432] res3_7 -> res3_7
I0527 16:08:31.207521 24728 net.cpp:170] Setting up res3_7
I0527 16:08:31.207521 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.207521 24728 net.cpp:185] Memory required for data: 49094656
I0527 16:08:31.208523 24728 layer_factory.hpp:77] Creating layer res3_7_res3_7_0_split
I0527 16:08:31.208523 24728 net.cpp:119] Creating Layer res3_7_res3_7_0_split
I0527 16:08:31.208523 24728 net.cpp:458] res3_7_res3_7_0_split <- res3_7
I0527 16:08:31.209527 24728 net.cpp:432] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_0
I0527 16:08:31.210528 24728 net.cpp:432] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_1
I0527 16:08:31.211531 24728 net.cpp:170] Setting up res3_7_res3_7_0_split
I0527 16:08:31.212533 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.213536 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.213536 24728 net.cpp:185] Memory required for data: 50143232
I0527 16:08:31.214540 24728 layer_factory.hpp:77] Creating layer conv3_8
I0527 16:08:31.215541 24728 net.cpp:119] Creating Layer conv3_8
I0527 16:08:31.216544 24728 net.cpp:458] conv3_8 <- res3_7_res3_7_0_split_0
I0527 16:08:31.216544 24728 net.cpp:432] conv3_8 -> conv3_8
I0527 16:08:31.222560 24728 net.cpp:170] Setting up conv3_8
I0527 16:08:31.222560 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.222560 24728 net.cpp:185] Memory required for data: 50667520
I0527 16:08:31.222560 24728 layer_factory.hpp:77] Creating layer relu3_8
I0527 16:08:31.222560 24728 net.cpp:119] Creating Layer relu3_8
I0527 16:08:31.222560 24728 net.cpp:458] relu3_8 <- conv3_8
I0527 16:08:31.223563 24728 net.cpp:417] relu3_8 -> conv3_8 (in-place)
I0527 16:08:31.223563 24728 net.cpp:170] Setting up relu3_8
I0527 16:08:31.223563 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.223563 24728 net.cpp:185] Memory required for data: 51191808
I0527 16:08:31.223563 24728 layer_factory.hpp:77] Creating layer conv3_9
I0527 16:08:31.224565 24728 net.cpp:119] Creating Layer conv3_9
I0527 16:08:31.224565 24728 net.cpp:458] conv3_9 <- conv3_8
I0527 16:08:31.224565 24728 net.cpp:432] conv3_9 -> conv3_9
I0527 16:08:31.228602 24728 net.cpp:170] Setting up conv3_9
I0527 16:08:31.228602 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.230581 24728 net.cpp:185] Memory required for data: 51716096
I0527 16:08:31.231583 24728 layer_factory.hpp:77] Creating layer relu3_9
I0527 16:08:31.232586 24728 net.cpp:119] Creating Layer relu3_9
I0527 16:08:31.234591 24728 net.cpp:458] relu3_9 <- conv3_9
I0527 16:08:31.235594 24728 net.cpp:417] relu3_9 -> conv3_9 (in-place)
I0527 16:08:31.236598 24728 net.cpp:170] Setting up relu3_9
I0527 16:08:31.237599 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.238602 24728 net.cpp:185] Memory required for data: 52240384
I0527 16:08:31.239605 24728 layer_factory.hpp:77] Creating layer res3_9
I0527 16:08:31.240607 24728 net.cpp:119] Creating Layer res3_9
I0527 16:08:31.241611 24728 net.cpp:458] res3_9 <- res3_7_res3_7_0_split_1
I0527 16:08:31.242614 24728 net.cpp:458] res3_9 <- conv3_9
I0527 16:08:31.243615 24728 net.cpp:432] res3_9 -> res3_9
I0527 16:08:31.244617 24728 net.cpp:170] Setting up res3_9
I0527 16:08:31.244617 24728 net.cpp:177] Top shape: 128 64 4 4 (131072)
I0527 16:08:31.245621 24728 net.cpp:185] Memory required for data: 52764672
I0527 16:08:31.246624 24728 layer_factory.hpp:77] Creating layer conv4_1
I0527 16:08:31.246624 24728 net.cpp:119] Creating Layer conv4_1
I0527 16:08:31.247627 24728 net.cpp:458] conv4_1 <- res3_9
I0527 16:08:31.247627 24728 net.cpp:432] conv4_1 -> conv4_1
I0527 16:08:31.250634 24728 net.cpp:170] Setting up conv4_1
I0527 16:08:31.250634 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.251637 24728 net.cpp:185] Memory required for data: 53026816
I0527 16:08:31.251637 24728 layer_factory.hpp:77] Creating layer relu4_1
I0527 16:08:31.251637 24728 net.cpp:119] Creating Layer relu4_1
I0527 16:08:31.251637 24728 net.cpp:458] relu4_1 <- conv4_1
I0527 16:08:31.251637 24728 net.cpp:417] relu4_1 -> conv4_1 (in-place)
I0527 16:08:31.252640 24728 net.cpp:170] Setting up relu4_1
I0527 16:08:31.252640 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.252640 24728 net.cpp:185] Memory required for data: 53288960
I0527 16:08:31.253641 24728 layer_factory.hpp:77] Creating layer conv4_1_relu4_1_0_split
I0527 16:08:31.254644 24728 net.cpp:119] Creating Layer conv4_1_relu4_1_0_split
I0527 16:08:31.255648 24728 net.cpp:458] conv4_1_relu4_1_0_split <- conv4_1
I0527 16:08:31.257653 24728 net.cpp:432] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_0
I0527 16:08:31.257653 24728 net.cpp:432] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_1
I0527 16:08:31.259658 24728 net.cpp:170] Setting up conv4_1_relu4_1_0_split
I0527 16:08:31.259658 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.260661 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.260661 24728 net.cpp:185] Memory required for data: 53813248
I0527 16:08:31.261664 24728 layer_factory.hpp:77] Creating layer conv4_2
I0527 16:08:31.262666 24728 net.cpp:119] Creating Layer conv4_2
I0527 16:08:31.262666 24728 net.cpp:458] conv4_2 <- conv4_1_relu4_1_0_split_0
I0527 16:08:31.263669 24728 net.cpp:432] conv4_2 -> conv4_2
I0527 16:08:31.267679 24728 net.cpp:170] Setting up conv4_2
I0527 16:08:31.267679 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.267679 24728 net.cpp:185] Memory required for data: 54075392
I0527 16:08:31.267679 24728 layer_factory.hpp:77] Creating layer relu4_2
I0527 16:08:31.267679 24728 net.cpp:119] Creating Layer relu4_2
I0527 16:08:31.268682 24728 net.cpp:458] relu4_2 <- conv4_2
I0527 16:08:31.268682 24728 net.cpp:417] relu4_2 -> conv4_2 (in-place)
I0527 16:08:31.268682 24728 net.cpp:170] Setting up relu4_2
I0527 16:08:31.268682 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.268682 24728 net.cpp:185] Memory required for data: 54337536
I0527 16:08:31.268682 24728 layer_factory.hpp:77] Creating layer conv4_3
I0527 16:08:31.269686 24728 net.cpp:119] Creating Layer conv4_3
I0527 16:08:31.270687 24728 net.cpp:458] conv4_3 <- conv4_2
I0527 16:08:31.272692 24728 net.cpp:432] conv4_3 -> conv4_3
I0527 16:08:31.278708 24728 net.cpp:170] Setting up conv4_3
I0527 16:08:31.278708 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.279712 24728 net.cpp:185] Memory required for data: 54599680
I0527 16:08:31.279712 24728 layer_factory.hpp:77] Creating layer relu4_3
I0527 16:08:31.279712 24728 net.cpp:119] Creating Layer relu4_3
I0527 16:08:31.279712 24728 net.cpp:458] relu4_3 <- conv4_3
I0527 16:08:31.280714 24728 net.cpp:417] relu4_3 -> conv4_3 (in-place)
I0527 16:08:31.280714 24728 net.cpp:170] Setting up relu4_3
I0527 16:08:31.280714 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.281718 24728 net.cpp:185] Memory required for data: 54861824
I0527 16:08:31.281718 24728 layer_factory.hpp:77] Creating layer res4_3
I0527 16:08:31.282721 24728 net.cpp:119] Creating Layer res4_3
I0527 16:08:31.282721 24728 net.cpp:458] res4_3 <- conv4_1_relu4_1_0_split_1
I0527 16:08:31.282721 24728 net.cpp:458] res4_3 <- conv4_3
I0527 16:08:31.282721 24728 net.cpp:432] res4_3 -> res4_3
I0527 16:08:31.283722 24728 net.cpp:170] Setting up res4_3
I0527 16:08:31.283722 24728 net.cpp:177] Top shape: 128 128 2 2 (65536)
I0527 16:08:31.283722 24728 net.cpp:185] Memory required for data: 55123968
I0527 16:08:31.283722 24728 layer_factory.hpp:77] Creating layer fc5
I0527 16:08:31.283722 24728 net.cpp:119] Creating Layer fc5
I0527 16:08:31.283722 24728 net.cpp:458] fc5 <- res4_3
I0527 16:08:31.284725 24728 net.cpp:432] fc5 -> fc5
I0527 16:08:31.284725 24728 net.cpp:170] Setting up fc5
I0527 16:08:31.284725 24728 net.cpp:177] Top shape: 128 48 (6144)
I0527 16:08:31.284725 24728 net.cpp:185] Memory required for data: 55148544
I0527 16:08:31.284725 24728 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0527 16:08:31.285727 24728 net.cpp:119] Creating Layer fc5_fc5_0_split
I0527 16:08:31.285727 24728 net.cpp:458] fc5_fc5_0_split <- fc5
I0527 16:08:31.285727 24728 net.cpp:432] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0527 16:08:31.285727 24728 net.cpp:432] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0527 16:08:31.285727 24728 net.cpp:432] fc5_fc5_0_split -> fc5_fc5_0_split_2
I0527 16:08:31.285727 24728 net.cpp:170] Setting up fc5_fc5_0_split
I0527 16:08:31.285727 24728 net.cpp:177] Top shape: 128 48 (6144)
I0527 16:08:31.286731 24728 net.cpp:177] Top shape: 128 48 (6144)
I0527 16:08:31.286731 24728 net.cpp:177] Top shape: 128 48 (6144)
I0527 16:08:31.286731 24728 net.cpp:185] Memory required for data: 55222272
I0527 16:08:31.286731 24728 layer_factory.hpp:77] Creating layer softmax_loss
I0527 16:08:31.286731 24728 net.cpp:119] Creating Layer softmax_loss
I0527 16:08:31.286731 24728 net.cpp:458] softmax_loss <- fc5_fc5_0_split_0
I0527 16:08:31.286731 24728 net.cpp:458] softmax_loss <- label_data_1_split_0
I0527 16:08:31.286731 24728 net.cpp:432] softmax_loss -> softmax_loss
I0527 16:08:31.286731 24728 layer_factory.hpp:77] Creating layer softmax_loss
I0527 16:08:31.287734 24728 net.cpp:170] Setting up softmax_loss
I0527 16:08:31.288735 24728 net.cpp:177] Top shape: (1)
I0527 16:08:31.288735 24728 net.cpp:180]     with loss weight 1
I0527 16:08:31.288735 24728 net.cpp:185] Memory required for data: 55222276
I0527 16:08:31.288735 24728 layer_factory.hpp:77] Creating layer accuracy_top1
I0527 16:08:31.288735 24728 net.cpp:119] Creating Layer accuracy_top1
I0527 16:08:31.288735 24728 net.cpp:458] accuracy_top1 <- fc5_fc5_0_split_1
I0527 16:08:31.290740 24728 net.cpp:458] accuracy_top1 <- label_data_1_split_1
I0527 16:08:31.291743 24728 net.cpp:432] accuracy_top1 -> accuracy_top1
I0527 16:08:31.292745 24728 net.cpp:170] Setting up accuracy_top1
I0527 16:08:31.293748 24728 net.cpp:177] Top shape: (1)
I0527 16:08:31.294751 24728 net.cpp:185] Memory required for data: 55222280
I0527 16:08:31.295753 24728 layer_factory.hpp:77] Creating layer accuracy_top5
I0527 16:08:31.295753 24728 net.cpp:119] Creating Layer accuracy_top5
I0527 16:08:31.296756 24728 net.cpp:458] accuracy_top5 <- fc5_fc5_0_split_2
I0527 16:08:31.296756 24728 net.cpp:458] accuracy_top5 <- label_data_1_split_2
I0527 16:08:31.297760 24728 net.cpp:432] accuracy_top5 -> accuracy_top5
I0527 16:08:31.297760 24728 net.cpp:170] Setting up accuracy_top5
I0527 16:08:31.298761 24728 net.cpp:177] Top shape: (1)
I0527 16:08:31.298761 24728 net.cpp:185] Memory required for data: 55222284
I0527 16:08:31.298761 24728 net.cpp:249] accuracy_top5 does not need backward computation.
I0527 16:08:31.298761 24728 net.cpp:249] accuracy_top1 does not need backward computation.
I0527 16:08:31.298761 24728 net.cpp:246] softmax_loss needs backward computation.
I0527 16:08:31.299764 24728 net.cpp:246] fc5_fc5_0_split needs backward computation.
I0527 16:08:31.299764 24728 net.cpp:246] fc5 needs backward computation.
I0527 16:08:31.299764 24728 net.cpp:246] res4_3 needs backward computation.
I0527 16:08:31.299764 24728 net.cpp:246] relu4_3 needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] conv4_3 needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] relu4_2 needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] conv4_2 needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] conv4_1_relu4_1_0_split needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] relu4_1 needs backward computation.
I0527 16:08:31.300767 24728 net.cpp:246] conv4_1 needs backward computation.
I0527 16:08:31.301769 24728 net.cpp:246] res3_9 needs backward computation.
I0527 16:08:31.301769 24728 net.cpp:246] relu3_9 needs backward computation.
I0527 16:08:31.302772 24728 net.cpp:246] conv3_9 needs backward computation.
I0527 16:08:31.303774 24728 net.cpp:246] relu3_8 needs backward computation.
I0527 16:08:31.304777 24728 net.cpp:246] conv3_8 needs backward computation.
I0527 16:08:31.305780 24728 net.cpp:246] res3_7_res3_7_0_split needs backward computation.
I0527 16:08:31.306783 24728 net.cpp:246] res3_7 needs backward computation.
I0527 16:08:31.307785 24728 net.cpp:246] relu3_7 needs backward computation.
I0527 16:08:31.307785 24728 net.cpp:246] conv3_7 needs backward computation.
I0527 16:08:31.308789 24728 net.cpp:246] relu3_6 needs backward computation.
I0527 16:08:31.310793 24728 net.cpp:246] conv3_6 needs backward computation.
I0527 16:08:31.310793 24728 net.cpp:246] res3_5_res3_5_0_split needs backward computation.
I0527 16:08:31.311796 24728 net.cpp:246] res3_5 needs backward computation.
I0527 16:08:31.311796 24728 net.cpp:246] relu3_5 needs backward computation.
I0527 16:08:31.311796 24728 net.cpp:246] conv3_5 needs backward computation.
I0527 16:08:31.311796 24728 net.cpp:246] relu3_4 needs backward computation.
I0527 16:08:31.312800 24728 net.cpp:246] conv3_4 needs backward computation.
I0527 16:08:31.312800 24728 net.cpp:246] res3_3_res3_3_0_split needs backward computation.
I0527 16:08:31.312800 24728 net.cpp:246] res3_3 needs backward computation.
I0527 16:08:31.312800 24728 net.cpp:246] relu3_3 needs backward computation.
I0527 16:08:31.312800 24728 net.cpp:246] conv3_3 needs backward computation.
I0527 16:08:31.313803 24728 net.cpp:246] relu3_2 needs backward computation.
I0527 16:08:31.313803 24728 net.cpp:246] conv3_2 needs backward computation.
I0527 16:08:31.313803 24728 net.cpp:246] conv3_1_relu3_1_0_split needs backward computation.
I0527 16:08:31.314805 24728 net.cpp:246] relu3_1 needs backward computation.
I0527 16:08:31.315809 24728 net.cpp:246] conv3_1 needs backward computation.
I0527 16:08:31.316812 24728 net.cpp:246] res2_5 needs backward computation.
I0527 16:08:31.317814 24728 net.cpp:246] relu2_5 needs backward computation.
I0527 16:08:31.318816 24728 net.cpp:246] conv2_5 needs backward computation.
I0527 16:08:31.320821 24728 net.cpp:246] relu2_4 needs backward computation.
I0527 16:08:31.320821 24728 net.cpp:246] conv2_4 needs backward computation.
I0527 16:08:31.321825 24728 net.cpp:246] res2_3_res2_3_0_split needs backward computation.
I0527 16:08:31.322827 24728 net.cpp:246] res2_3 needs backward computation.
I0527 16:08:31.323829 24728 net.cpp:246] relu2_3 needs backward computation.
I0527 16:08:31.323829 24728 net.cpp:246] conv2_3 needs backward computation.
I0527 16:08:31.323829 24728 net.cpp:246] relu2_2 needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] conv2_2 needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] conv2_1_relu2_1_0_split needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] relu2_1 needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] conv2_1 needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] res1_3 needs backward computation.
I0527 16:08:31.324832 24728 net.cpp:246] relu1_3 needs backward computation.
I0527 16:08:31.325834 24728 net.cpp:246] conv1_3 needs backward computation.
I0527 16:08:31.325834 24728 net.cpp:246] relu1_2 needs backward computation.
I0527 16:08:31.325834 24728 net.cpp:246] conv1_2 needs backward computation.
I0527 16:08:31.325834 24728 net.cpp:246] conv1_1_relu1_1_0_split needs backward computation.
I0527 16:08:31.325834 24728 net.cpp:246] relu1_1 needs backward computation.
I0527 16:08:31.326838 24728 net.cpp:246] conv1_1 needs backward computation.
I0527 16:08:31.326838 24728 net.cpp:249] label_data_1_split does not need backward computation.
I0527 16:08:31.326838 24728 net.cpp:249] data does not need backward computation.
I0527 16:08:31.326838 24728 net.cpp:292] This network produces output accuracy_top1
I0527 16:08:31.326838 24728 net.cpp:292] This network produces output accuracy_top5
I0527 16:08:31.326838 24728 net.cpp:292] This network produces output softmax_loss
I0527 16:08:31.327838 24728 net.cpp:305] Network initialization done.
I0527 16:08:31.327838 24728 solver.cpp:60] Solver scaffolding done.
I0527 16:08:31.330847 24728 caffe.cpp:250] Starting Optimization
I0527 16:08:31.335861 24728 parallel.cpp:765] GPUs pairs 0:1
I0527 16:08:31.434121 24728 data_layer.cpp:41] output data size: 128,3,30,30
I0527 16:08:32.191139 24728 parallel.cpp:606] GPU 1 does not have p2p access to GPU 0
I0527 16:08:32.192142 24728 parallel.cpp:798] Starting Optimization
I0527 16:08:32.193145 24728 solver.cpp:283] Solving ResNet20
I0527 16:08:32.194147 24728 solver.cpp:284] Learning Rate Policy: multistep
I0527 16:08:32.238265 24728 solver.cpp:232] Iteration 0, loss = 7.49325
I0527 16:08:32.238265 24728 solver.cpp:248]     Train net output #0: softmax_loss = 7.49325 (* 1 = 7.49325 loss)
I0527 16:08:32.239267 24728 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0527 16:08:32.246286 24728 sgd_solver.cpp:143] prelu slope:0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 0.100000 
I0527 16:08:32.257315 24728 sgd_solver.cpp:158] weight diff/data(L1):0.086045 0.047194 0.053085 0.067308 0.146393 0.099800 0.097907 0.072872 0.058185 0.071867 0.049691 0.039077 0.049200 0.038602 0.040384 0.062254 0.055129 0.077989 0.025566 0.042936 0.154848 
I0527 16:08:33.870604 24728 solver.cpp:232] Iteration 100, loss = 8.61219e-05
I0527 16:08:33.870604 24728 solver.cpp:248]     Train net output #0: softmax_loss = 8.61963e-05 (* 1 = 8.61963e-05 loss)
I0527 16:08:33.877621 24728 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0527 16:08:33.882635 24728 sgd_solver.cpp:143] prelu slope:0.126906 0.099540 0.099672 0.118032 0.099476 0.099652 0.099581 0.099763 0.111567 0.099604 0.099811 0.099608 0.099768 0.099553 0.099771 0.099449 0.099868 0.104860 0.099558 0.099670 
I0527 16:08:33.888653 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000093 0.000078 0.000071 0.000265 0.000120 0.000109 0.000104 0.000132 0.000097 0.000097 0.000095 0.000088 0.000376 0.000099 0.000089 0.000090 0.000096 0.000139 0.000103 0.000108 0.000165 
I0527 16:08:34.165386 24728 blocking_queue.cpp:50] Data layer prefetch queue empty
I0527 16:08:34.288744 24728 solver.cpp:341] Iteration 125, Testing net (#0)
I0527 16:08:34.338877 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 0.998884
I0527 16:08:34.338877 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:34.338877 24728 solver.cpp:410]     Test net output #2: softmax_loss = 0.00193866 (* 1 = 0.00193866 loss)
I0527 16:08:35.562160 24728 solver.cpp:232] Iteration 200, loss = 6.84352e-05
I0527 16:08:35.562160 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.85096e-05 (* 1 = 6.85096e-05 loss)
I0527 16:08:35.569177 24728 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0527 16:08:35.572186 24728 sgd_solver.cpp:143] prelu slope:0.127309 0.099042 0.099179 0.117579 0.098982 0.099155 0.099086 0.099263 0.111003 0.099107 0.099315 0.099114 0.099273 0.099056 0.099273 0.098952 0.099372 0.104340 0.099060 0.099173 
I0527 16:08:35.577198 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000222 0.000102 0.000096 0.000131 0.000122 0.000155 0.000137 0.000177 0.000364 0.000134 0.000486 0.000138 0.000128 0.000126 0.000122 0.000125 0.000134 0.000215 0.000103 0.000204 0.000179 
I0527 16:08:36.377352 24728 solver.cpp:341] Iteration 250, Testing net (#0)
I0527 16:08:36.415454 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:36.415454 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:36.416457 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.38649e-05 (* 1 = 5.38649e-05 loss)
I0527 16:08:37.242660 24728 solver.cpp:232] Iteration 300, loss = 5.19551e-05
I0527 16:08:37.242660 24728 solver.cpp:248]     Train net output #0: softmax_loss = 5.20296e-05 (* 1 = 5.20296e-05 loss)
I0527 16:08:37.248674 24728 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0527 16:08:37.253688 24728 sgd_solver.cpp:143] prelu slope:0.126707 0.098548 0.098684 0.117159 0.098488 0.098663 0.098591 0.098770 0.110477 0.098612 0.098820 0.098619 0.098778 0.098562 0.098778 0.098459 0.098876 0.103823 0.098566 0.098678 
I0527 16:08:37.259704 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000116 0.000108 0.000079 0.000088 0.000093 0.000111 0.000095 0.000218 0.000235 0.000092 0.000304 0.000207 0.000106 0.000122 0.000254 0.000193 0.000094 0.000395 0.000080 0.000117 0.000135 
I0527 16:08:38.465910 24728 solver.cpp:341] Iteration 375, Testing net (#0)
I0527 16:08:38.505014 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:38.505014 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:38.507020 24728 solver.cpp:410]     Test net output #2: softmax_loss = 4.72807e-05 (* 1 = 4.72807e-05 loss)
I0527 16:08:38.928139 24728 solver.cpp:232] Iteration 400, loss = 6.67377e-05
I0527 16:08:38.929141 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.68122e-05 (* 1 = 6.68122e-05 loss)
I0527 16:08:38.935158 24728 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0527 16:08:38.939168 24728 sgd_solver.cpp:143] prelu slope:0.126202 0.098056 0.098191 0.116719 0.097996 0.098173 0.098099 0.098279 0.109945 0.098120 0.098327 0.098127 0.098285 0.098070 0.098285 0.097967 0.098383 0.103324 0.098074 0.098185 
I0527 16:08:38.944180 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000234 0.000055 0.000057 0.000688 0.000057 0.000058 0.000063 0.000061 0.000062 0.000068 0.000058 0.000061 0.000078 0.000059 0.000056 0.000064 0.000061 0.000096 0.000055 0.000059 0.000066 
I0527 16:08:40.578526 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_500.caffemodel
I0527 16:08:40.605599 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_500.solverstate
I0527 16:08:40.614622 24728 solver.cpp:341] Iteration 500, Testing net (#0)
I0527 16:08:40.654728 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:40.655731 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:40.655731 24728 solver.cpp:410]     Test net output #2: softmax_loss = 4.19526e-05 (* 1 = 4.19526e-05 loss)
I0527 16:08:40.661747 24728 solver.cpp:232] Iteration 500, loss = 3.43278e-05
I0527 16:08:40.662750 24728 solver.cpp:248]     Train net output #0: softmax_loss = 3.44023e-05 (* 1 = 3.44023e-05 loss)
I0527 16:08:40.671773 24728 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0527 16:08:40.674782 24728 sgd_solver.cpp:143] prelu slope:0.125720 0.097566 0.097702 0.116270 0.097507 0.097685 0.097609 0.097790 0.109417 0.097631 0.097837 0.097638 0.097795 0.097581 0.097795 0.097479 0.097892 0.102826 0.097585 0.097696 
I0527 16:08:40.680797 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000108 0.000056 0.000234 0.000070 0.000060 0.000060 0.004854 0.000065 0.000065 0.000067 0.000058 0.000086 0.000064 0.000063 0.000056 0.000070 0.000060 0.000068 0.000066 0.000093 0.000069 
I0527 16:08:42.294086 24728 solver.cpp:232] Iteration 600, loss = 7.58397e-05
I0527 16:08:42.294086 24728 solver.cpp:248]     Train net output #0: softmax_loss = 7.59142e-05 (* 1 = 7.59142e-05 loss)
I0527 16:08:42.301105 24728 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0527 16:08:42.303109 24728 sgd_solver.cpp:143] prelu slope:0.125236 0.097079 0.097214 0.115823 0.097021 0.097200 0.097122 0.097304 0.108893 0.097144 0.097349 0.097150 0.097307 0.097094 0.097307 0.096992 0.097404 0.102330 0.097098 0.097208 
I0527 16:08:42.310127 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000070 0.000056 0.000060 0.000060 0.000060 0.000061 0.000089 0.000067 0.000062 0.000057 0.000077 0.000059 0.000056 0.000070 0.000056 0.000063 0.000055 0.000075 0.000055 0.000059 0.000074 
I0527 16:08:42.702170 24728 solver.cpp:341] Iteration 625, Testing net (#0)
I0527 16:08:42.739269 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:42.739269 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:42.739269 24728 solver.cpp:410]     Test net output #2: softmax_loss = 4.85943e-05 (* 1 = 4.85943e-05 loss)
I0527 16:08:43.956506 24728 solver.cpp:232] Iteration 700, loss = 6.09257e-05
I0527 16:08:43.956506 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.10002e-05 (* 1 = 6.10002e-05 loss)
I0527 16:08:43.963522 24728 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0527 16:08:43.966531 24728 sgd_solver.cpp:143] prelu slope:0.124781 0.096594 0.096730 0.115366 0.096537 0.096717 0.096637 0.096820 0.108373 0.096659 0.096863 0.096666 0.096821 0.096610 0.096822 0.096508 0.096918 0.101836 0.096613 0.096723 
I0527 16:08:43.973549 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000069 0.000065 0.000065 0.000072 0.000080 0.000153 0.000093 0.000086 0.000082 0.000073 0.000070 0.000072 0.000073 0.000091 0.000064 0.000083 0.000065 0.000099 0.000062 0.000075 0.000077 
I0527 16:08:44.763650 24728 solver.cpp:341] Iteration 750, Testing net (#0)
I0527 16:08:44.800748 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:44.800748 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:44.800748 24728 solver.cpp:410]     Test net output #2: softmax_loss = 4.65061e-05 (* 1 = 4.65061e-05 loss)
I0527 16:08:45.632966 24728 solver.cpp:232] Iteration 800, loss = 3.42248e-05
I0527 16:08:45.632966 24728 solver.cpp:248]     Train net output #0: softmax_loss = 3.42993e-05 (* 1 = 3.42993e-05 loss)
I0527 16:08:45.638981 24728 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0527 16:08:45.648005 24728 sgd_solver.cpp:143] prelu slope:0.124276 0.096111 0.096247 0.114932 0.096055 0.096236 0.096155 0.096338 0.107856 0.096177 0.096380 0.096183 0.096338 0.096128 0.096339 0.096027 0.096435 0.101339 0.096131 0.096241 
I0527 16:08:45.656026 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000064 0.000101 0.000060 0.000099 0.000109 0.000090 0.000066 0.000075 0.000071 0.000088 0.000066 0.000101 0.000067 0.000084 0.000093 0.000079 0.000065 0.000084 0.000067 0.000063 0.000080 
I0527 16:08:46.867246 24728 solver.cpp:341] Iteration 875, Testing net (#0)
I0527 16:08:46.908356 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:46.908356 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:46.909358 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.197e-05 (* 1 = 5.197e-05 loss)
I0527 16:08:47.328472 24728 solver.cpp:232] Iteration 900, loss = 6.40442e-05
I0527 16:08:47.328472 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.41187e-05 (* 1 = 6.41187e-05 loss)
I0527 16:08:47.335490 24728 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0527 16:08:47.343513 24728 sgd_solver.cpp:143] prelu slope:0.123786 0.095631 0.095767 0.114506 0.095576 0.095758 0.095675 0.095860 0.107341 0.095697 0.095899 0.095703 0.095857 0.095648 0.095858 0.095548 0.095954 0.100848 0.095652 0.095761 
I0527 16:08:47.351536 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000065 0.000067 0.000053 0.000065 0.000135 0.000064 0.000060 0.000060 0.000070 0.000064 0.000055 0.000055 0.000063 0.000061 0.000055 0.000056 0.000056 0.000061 0.000054 0.000054 0.000062 
I0527 16:08:48.974855 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_1000.caffemodel
I0527 16:08:49.025990 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_1000.solverstate
I0527 16:08:49.076124 24728 solver.cpp:341] Iteration 1000, Testing net (#0)
I0527 16:08:49.113221 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:49.114225 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:49.116230 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.05641e-05 (* 1 = 5.05641e-05 loss)
I0527 16:08:49.125255 24728 solver.cpp:232] Iteration 1000, loss = 4.81467e-05
I0527 16:08:49.125255 24728 solver.cpp:248]     Train net output #0: softmax_loss = 4.82212e-05 (* 1 = 4.82212e-05 loss)
I0527 16:08:49.132272 24728 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0527 16:08:49.137285 24728 sgd_solver.cpp:143] prelu slope:0.123332 0.095154 0.095289 0.114084 0.095099 0.095283 0.095198 0.095383 0.106829 0.095220 0.095421 0.095226 0.095379 0.095171 0.095380 0.095071 0.095475 0.100362 0.095174 0.095283 
I0527 16:08:49.142299 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000070 0.000058 0.000053 0.000063 0.000083 0.000062 0.000060 0.000060 0.000070 0.000064 0.000104 0.000059 0.000061 0.000063 0.000058 0.000057 0.000058 0.000068 0.000059 0.000060 0.000067 
I0527 16:08:50.773635 24728 solver.cpp:232] Iteration 1100, loss = 3.29349e-05
I0527 16:08:50.773635 24728 solver.cpp:248]     Train net output #0: softmax_loss = 3.30095e-05 (* 1 = 3.30095e-05 loss)
I0527 16:08:50.780654 24728 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0527 16:08:50.782660 24728 sgd_solver.cpp:143] prelu slope:0.122884 0.094678 0.094814 0.113669 0.094624 0.094810 0.094723 0.094909 0.106322 0.094745 0.094945 0.094751 0.094903 0.094696 0.094904 0.094597 0.094999 0.099878 0.094700 0.094808 
I0527 16:08:50.790680 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000061 0.000066 0.000055 0.000061 0.000069 0.000060 0.000060 0.000062 0.000071 0.000069 0.000057 0.000056 0.000056 0.000404 0.000058 0.000058 0.000059 0.000060 0.000056 0.000068 0.000074 
I0527 16:08:51.186734 24728 solver.cpp:341] Iteration 1125, Testing net (#0)
I0527 16:08:51.221827 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:51.221827 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:51.222831 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.00329e-05 (* 1 = 6.00329e-05 loss)
I0527 16:08:52.444087 24728 solver.cpp:232] Iteration 1200, loss = 5.73618e-05
I0527 16:08:52.444087 24728 solver.cpp:248]     Train net output #0: softmax_loss = 5.74364e-05 (* 1 = 5.74364e-05 loss)
I0527 16:08:52.451104 24728 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0527 16:08:52.456118 24728 sgd_solver.cpp:143] prelu slope:0.122457 0.094206 0.094341 0.113248 0.094152 0.094339 0.094250 0.094437 0.105818 0.094272 0.094472 0.094278 0.094430 0.094224 0.094431 0.094125 0.094525 0.099398 0.094227 0.094335 
I0527 16:08:52.462134 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000058 0.000091 0.000060 0.000060 0.000067 0.000068 0.000074 0.000070 0.000067 0.000106 0.000066 0.000058 0.000063 0.000094 0.000061 0.000067 0.000067 0.000078 0.000059 0.000063 0.000068 
I0527 16:08:53.253237 24728 solver.cpp:341] Iteration 1250, Testing net (#0)
I0527 16:08:53.287326 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:53.288329 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:53.289332 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.43903e-05 (* 1 = 5.43903e-05 loss)
I0527 16:08:54.103497 24728 solver.cpp:232] Iteration 1300, loss = 6.2539e-05
I0527 16:08:54.103497 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.26136e-05 (* 1 = 6.26136e-05 loss)
I0527 16:08:54.110515 24728 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0527 16:08:54.113523 24728 sgd_solver.cpp:143] prelu slope:0.122004 0.093735 0.093871 0.112843 0.093683 0.093871 0.093780 0.093968 0.105318 0.093802 0.094001 0.093808 0.093959 0.093754 0.093960 0.093655 0.094053 0.098915 0.093757 0.093864 
I0527 16:08:54.120542 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000059 0.000070 0.000058 0.000059 0.000067 0.000065 0.000166 0.000062 0.000084 0.000065 0.000062 0.000061 0.000106 0.000062 0.000059 0.000638 0.000060 0.000120 0.000058 0.000057 0.000074 
I0527 16:08:55.312737 24728 solver.cpp:341] Iteration 1375, Testing net (#0)
I0527 16:08:55.349809 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:55.349809 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:55.350812 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.58527e-05 (* 1 = 6.58527e-05 loss)
I0527 16:08:55.769927 24728 solver.cpp:232] Iteration 1400, loss = 0.000163048
I0527 16:08:55.769927 24728 solver.cpp:248]     Train net output #0: softmax_loss = 0.000163123 (* 1 = 0.000163123 loss)
I0527 16:08:55.776944 24728 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0527 16:08:55.780956 24728 sgd_solver.cpp:143] prelu slope:0.121546 0.093267 0.093403 0.112449 0.093215 0.093405 0.093312 0.093501 0.104821 0.093334 0.093532 0.093340 0.093490 0.093286 0.093491 0.093188 0.093584 0.098438 0.093289 0.093396 
I0527 16:08:55.787974 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000064 0.000059 0.000055 0.000059 0.000062 0.000061 0.000082 0.000063 0.000061 0.000071 0.000060 0.000059 0.000085 0.000063 0.000059 0.000125 0.000063 0.000063 0.000056 0.000058 0.000063 
I0527 16:08:57.399257 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_1500.caffemodel
I0527 16:08:57.421316 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_1500.solverstate
I0527 16:08:57.429338 24728 solver.cpp:341] Iteration 1500, Testing net (#0)
I0527 16:08:57.465433 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:57.465433 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:57.465433 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.89098e-05 (* 1 = 5.89098e-05 loss)
I0527 16:08:57.474457 24728 solver.cpp:232] Iteration 1500, loss = 0.000207442
I0527 16:08:57.474457 24728 solver.cpp:248]     Train net output #0: softmax_loss = 0.000207517 (* 1 = 0.000207517 loss)
I0527 16:08:57.480473 24728 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0527 16:08:57.487493 24728 sgd_solver.cpp:143] prelu slope:0.121126 0.092801 0.092937 0.112059 0.092750 0.092942 0.092846 0.093037 0.104326 0.092868 0.093065 0.092874 0.093023 0.092821 0.093025 0.092723 0.093117 0.097964 0.092824 0.092930 
I0527 16:08:57.494510 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000068 0.000062 0.000057 0.000060 0.000084 0.000070 0.000070 0.000072 0.000072 0.000063 0.000191 0.000072 0.000076 0.000069 0.000059 0.000073 0.000067 0.000085 0.000059 0.000061 0.000070 
I0527 16:08:59.103788 24728 solver.cpp:232] Iteration 1600, loss = 0.000118047
I0527 16:08:59.103788 24728 solver.cpp:248]     Train net output #0: softmax_loss = 0.000118122 (* 1 = 0.000118122 loss)
I0527 16:08:59.110806 24728 sgd_solver.cpp:46] MultiStep Status: Iteration 1600, step = 1
I0527 16:08:59.112812 24728 sgd_solver.cpp:106] Iteration 1600, lr = 0.002
I0527 16:08:59.117825 24728 sgd_solver.cpp:143] prelu slope:0.120710 0.092338 0.092473 0.111675 0.092287 0.092480 0.092383 0.092574 0.103835 0.092405 0.092601 0.092410 0.092559 0.092358 0.092561 0.092261 0.092653 0.097493 0.092361 0.092467 
I0527 16:08:59.125847 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000054 0.000056 0.000052 0.000053 0.000056 0.000054 0.000057 0.000055 0.000055 0.000068 0.000070 0.000056 0.000052 0.000055 0.000052 0.000059 0.000057 0.000056 0.000051 0.000050 0.000060 
I0527 16:08:59.515890 24728 solver.cpp:341] Iteration 1625, Testing net (#0)
I0527 16:08:59.550976 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:08:59.550976 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:08:59.552983 24728 solver.cpp:410]     Test net output #2: softmax_loss = 7.53827e-05 (* 1 = 7.53827e-05 loss)
I0527 16:09:00.775233 24728 solver.cpp:232] Iteration 1700, loss = 7.46911e-05
I0527 16:09:00.775233 24728 solver.cpp:248]     Train net output #0: softmax_loss = 7.47656e-05 (* 1 = 7.47656e-05 loss)
I0527 16:09:00.782250 24728 sgd_solver.cpp:106] Iteration 1700, lr = 0.002
I0527 16:09:00.786262 24728 sgd_solver.cpp:143] prelu slope:0.120602 0.092212 0.092348 0.111565 0.092162 0.092355 0.092257 0.092449 0.103703 0.092279 0.092475 0.092285 0.092433 0.092232 0.092435 0.092135 0.092527 0.097365 0.092235 0.092341 
I0527 16:09:00.793278 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000012 0.000013 0.000012 0.000012 0.000012 0.000012 0.000013 0.000014 0.000012 0.000016 0.000012 0.000012 0.000011 0.000013 0.000021 0.000012 0.000013 0.000012 0.000012 0.000011 0.000013 
I0527 16:09:01.584381 24728 solver.cpp:341] Iteration 1750, Testing net (#0)
I0527 16:09:01.619475 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:01.619475 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:01.620477 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.7241e-05 (* 1 = 5.7241e-05 loss)
I0527 16:09:02.428627 24728 solver.cpp:232] Iteration 1800, loss = 0.000102807
I0527 16:09:02.428627 24728 solver.cpp:248]     Train net output #0: softmax_loss = 0.000102881 (* 1 = 0.000102881 loss)
I0527 16:09:02.435672 24728 sgd_solver.cpp:106] Iteration 1800, lr = 0.002
I0527 16:09:02.439656 24728 sgd_solver.cpp:143] prelu slope:0.120518 0.092120 0.092255 0.111488 0.092070 0.092264 0.092165 0.092357 0.103605 0.092187 0.092383 0.092193 0.092341 0.092140 0.092343 0.092043 0.092435 0.097270 0.092143 0.092249 
I0527 16:09:02.446674 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000014 0.000015 0.000013 0.000012 0.000015 0.000014 0.000014 0.001116 0.000016 0.000030 0.000014 0.000015 0.000015 0.000020 0.000014 0.000028 0.000016 0.000019 0.000015 0.000014 0.000025 
I0527 16:09:03.642880 24728 solver.cpp:341] Iteration 1875, Testing net (#0)
I0527 16:09:03.678949 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:03.678949 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:03.679952 24728 solver.cpp:410]     Test net output #2: softmax_loss = 7.68376e-05 (* 1 = 7.68376e-05 loss)
I0527 16:09:04.094053 24728 solver.cpp:232] Iteration 1900, loss = 7.9075e-05
I0527 16:09:04.094053 24728 solver.cpp:248]     Train net output #0: softmax_loss = 7.91496e-05 (* 1 = 7.91496e-05 loss)
I0527 16:09:04.101073 24728 sgd_solver.cpp:106] Iteration 1900, lr = 0.002
I0527 16:09:04.105082 24728 sgd_solver.cpp:143] prelu slope:0.120432 0.092028 0.092163 0.111412 0.091978 0.092172 0.092073 0.092265 0.103508 0.092095 0.092291 0.092100 0.092249 0.092048 0.092250 0.091951 0.092342 0.097176 0.092051 0.092156 
I0527 16:09:04.112100 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000013 0.000012 0.000011 0.000012 0.000013 0.000012 0.000012 0.000016 0.000012 0.000026 0.000011 0.000012 0.000012 0.000016 0.000011 0.000013 0.000011 0.000012 0.000011 0.000016 0.000014 
I0527 16:09:05.708371 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_2000.caffemodel
I0527 16:09:05.731405 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_2000.solverstate
I0527 16:09:05.740430 24728 solver.cpp:341] Iteration 2000, Testing net (#0)
I0527 16:09:05.776526 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:05.776526 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:05.778532 24728 solver.cpp:410]     Test net output #2: softmax_loss = 5.72262e-05 (* 1 = 5.72262e-05 loss)
I0527 16:09:05.785550 24728 solver.cpp:232] Iteration 2000, loss = 4.55375e-05
I0527 16:09:05.785550 24728 solver.cpp:248]     Train net output #0: softmax_loss = 4.56121e-05 (* 1 = 4.56121e-05 loss)
I0527 16:09:05.792567 24728 sgd_solver.cpp:106] Iteration 2000, lr = 0.002
I0527 16:09:05.798583 24728 sgd_solver.cpp:143] prelu slope:0.120349 0.091936 0.092071 0.111336 0.091886 0.092080 0.091981 0.092173 0.103410 0.092002 0.092198 0.092008 0.092156 0.091956 0.092158 0.091859 0.092250 0.097083 0.091959 0.092064 
I0527 16:09:05.805603 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000012 0.000013 0.000012 0.000012 0.000110 0.000012 0.000013 0.000015 0.000013 0.000014 0.000011 0.000012 0.000013 0.000013 0.000012 0.000013 0.000012 0.000013 0.000012 0.000017 0.000013 
I0527 16:09:07.417888 24728 solver.cpp:232] Iteration 2100, loss = 5.8982e-05
I0527 16:09:07.418891 24728 solver.cpp:248]     Train net output #0: softmax_loss = 5.90566e-05 (* 1 = 5.90566e-05 loss)
I0527 16:09:07.425909 24728 sgd_solver.cpp:106] Iteration 2100, lr = 0.002
I0527 16:09:07.429921 24728 sgd_solver.cpp:143] prelu slope:0.120268 0.091844 0.091979 0.111260 0.091794 0.091989 0.091889 0.092082 0.103313 0.091911 0.092106 0.091916 0.092064 0.091864 0.092066 0.091768 0.092158 0.096989 0.091867 0.091972 
I0527 16:09:07.437942 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000011 0.000015 0.000012 0.000012 0.000014 0.000012 0.000013 0.000012 0.000023 0.000013 0.000012 0.000011 0.000013 0.000012 0.000012 0.000012 0.000011 0.000013 0.000011 0.000016 0.000014 
I0527 16:09:07.831990 24728 solver.cpp:341] Iteration 2125, Testing net (#0)
I0527 16:09:07.868085 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:07.868085 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:07.869087 24728 solver.cpp:410]     Test net output #2: softmax_loss = 8.03012e-05 (* 1 = 8.03012e-05 loss)
I0527 16:09:09.080307 24728 solver.cpp:232] Iteration 2200, loss = 6.43537e-05
I0527 16:09:09.080307 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.44283e-05 (* 1 = 6.44283e-05 loss)
I0527 16:09:09.087327 24728 sgd_solver.cpp:106] Iteration 2200, lr = 0.002
I0527 16:09:09.091336 24728 sgd_solver.cpp:143] prelu slope:0.120188 0.091752 0.091887 0.111183 0.091702 0.091897 0.091797 0.091990 0.103216 0.091819 0.092014 0.091825 0.091972 0.091772 0.091974 0.091676 0.092066 0.096896 0.091775 0.091880 
I0527 16:09:09.098356 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000012 0.000017 0.000015 0.000012 0.000018 0.000013 0.000017 0.000015 0.000016 0.000018 0.000014 0.000013 0.000043 0.000015 0.000015 0.000014 0.000012 0.000016 0.000014 0.000024 0.000014 
I0527 16:09:09.911545 24728 solver.cpp:341] Iteration 2250, Testing net (#0)
I0527 16:09:09.951623 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:09.952626 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:09.953629 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.25707e-05 (* 1 = 6.25707e-05 loss)
I0527 16:09:10.778822 24728 solver.cpp:232] Iteration 2300, loss = 4.29029e-05
I0527 16:09:10.778822 24728 solver.cpp:248]     Train net output #0: softmax_loss = 4.29774e-05 (* 1 = 4.29774e-05 loss)
I0527 16:09:10.786844 24728 sgd_solver.cpp:106] Iteration 2300, lr = 0.002
I0527 16:09:10.789851 24728 sgd_solver.cpp:143] prelu slope:0.120104 0.091660 0.091795 0.111107 0.091611 0.091806 0.091705 0.091899 0.103120 0.091727 0.091922 0.091733 0.091881 0.091681 0.091882 0.091584 0.091974 0.096802 0.091684 0.091789 
I0527 16:09:10.796870 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000013 0.000020 0.000013 0.000012 0.000014 0.000013 0.000012 0.000016 0.000154 0.000019 0.000013 0.000014 0.000016 0.000014 0.000013 0.000015 0.000014 0.000017 0.000015 0.000013 0.000015 
I0527 16:09:11.989044 24728 solver.cpp:341] Iteration 2375, Testing net (#0)
I0527 16:09:12.030153 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:12.030153 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:12.031155 24728 solver.cpp:410]     Test net output #2: softmax_loss = 7.45385e-05 (* 1 = 7.45385e-05 loss)
I0527 16:09:12.460296 24728 solver.cpp:232] Iteration 2400, loss = 5.39392e-05
I0527 16:09:12.460296 24728 solver.cpp:248]     Train net output #0: softmax_loss = 5.40138e-05 (* 1 = 5.40138e-05 loss)
I0527 16:09:12.467315 24728 sgd_solver.cpp:46] MultiStep Status: Iteration 2400, step = 2
I0527 16:09:12.467315 24728 sgd_solver.cpp:106] Iteration 2400, lr = 0.0004
I0527 16:09:12.472328 24728 sgd_solver.cpp:143] prelu slope:0.120018 0.091569 0.091704 0.111033 0.091519 0.091715 0.091614 0.091807 0.103023 0.091635 0.091831 0.091641 0.091789 0.091589 0.091791 0.091493 0.091882 0.096709 0.091592 0.091697 
I0527 16:09:12.478345 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000012 0.000014 0.000011 0.000011 0.000011 0.000011 0.000011 0.000012 0.000015 0.000012 0.000011 0.000011 0.000015 0.000011 0.000013 0.000011 0.000010 0.000013 0.000012 0.000010 0.000012 
I0527 16:09:14.092701 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_2500.caffemodel
I0527 16:09:14.113731 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_2500.solverstate
I0527 16:09:14.123757 24728 solver.cpp:341] Iteration 2500, Testing net (#0)
I0527 16:09:14.164866 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:14.164866 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:14.166872 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.30366e-05 (* 1 = 6.30366e-05 loss)
I0527 16:09:14.183943 24728 solver.cpp:232] Iteration 2500, loss = 6.13819e-05
I0527 16:09:14.183943 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.14565e-05 (* 1 = 6.14565e-05 loss)
I0527 16:09:14.183943 24728 sgd_solver.cpp:106] Iteration 2500, lr = 0.0004
I0527 16:09:14.193943 24728 sgd_solver.cpp:143] prelu slope:0.119996 0.091544 0.091679 0.111012 0.091494 0.091690 0.091589 0.091782 0.102996 0.091610 0.091806 0.091616 0.091764 0.091564 0.091766 0.091468 0.091857 0.096683 0.091567 0.091672 
I0527 16:09:14.199959 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000002 0.000004 0.000002 0.000002 0.000003 0.000002 0.000002 0.000003 0.000003 0.000003 0.000002 0.000003 0.000004 0.000002 0.000003 0.000002 0.000002 0.000003 0.000003 0.000002 0.000003 
I0527 16:09:15.814251 24728 solver.cpp:232] Iteration 2600, loss = 6.96207e-05
I0527 16:09:15.815253 24728 solver.cpp:248]     Train net output #0: softmax_loss = 6.96954e-05 (* 1 = 6.96954e-05 loss)
I0527 16:09:15.822273 24728 sgd_solver.cpp:106] Iteration 2600, lr = 0.0004
I0527 16:09:15.829293 24728 sgd_solver.cpp:143] prelu slope:0.119980 0.091525 0.091660 0.110997 0.091476 0.091672 0.091570 0.091764 0.102977 0.091592 0.091787 0.091598 0.091745 0.091546 0.091747 0.091449 0.091838 0.096665 0.091549 0.091653 
I0527 16:09:15.838315 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000002 0.000006 0.000003 0.000002 0.000002 0.000002 0.000002 0.000003 0.000008 0.000003 0.000002 0.000002 0.000003 0.000002 0.000003 0.000002 0.000002 0.000003 0.000002 0.000002 0.000002 
I0527 16:09:16.230356 24728 solver.cpp:341] Iteration 2625, Testing net (#0)
I0527 16:09:16.270464 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:16.270464 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:16.272469 24728 solver.cpp:410]     Test net output #2: softmax_loss = 7.46171e-05 (* 1 = 7.46171e-05 loss)
I0527 16:09:17.512792 24728 solver.cpp:232] Iteration 2700, loss = 5.5384e-05
I0527 16:09:17.512792 24728 solver.cpp:248]     Train net output #0: softmax_loss = 5.54587e-05 (* 1 = 5.54587e-05 loss)
I0527 16:09:17.519785 24728 sgd_solver.cpp:106] Iteration 2700, lr = 0.0004
I0527 16:09:17.524798 24728 sgd_solver.cpp:143] prelu slope:0.119964 0.091507 0.091642 0.110982 0.091457 0.091653 0.091552 0.091745 0.102958 0.091573 0.091769 0.091579 0.091727 0.091527 0.091728 0.091431 0.091820 0.096646 0.091530 0.091635 
I0527 16:09:17.532819 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000002 0.000006 0.000003 0.000002 0.000003 0.000003 0.000003 0.000003 0.000004 0.000003 0.000003 0.000003 0.000003 0.000002 0.000003 0.000002 0.000002 0.000003 0.000002 0.000002 0.000003 
I0527 16:09:18.337960 24728 solver.cpp:341] Iteration 2750, Testing net (#0)
I0527 16:09:18.374055 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:18.374055 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:18.375084 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.39409e-05 (* 1 = 6.39409e-05 loss)
I0527 16:09:19.201254 24728 solver.cpp:232] Iteration 2800, loss = 7.93678e-05
I0527 16:09:19.201254 24728 solver.cpp:248]     Train net output #0: softmax_loss = 7.94425e-05 (* 1 = 7.94425e-05 loss)
I0527 16:09:19.209276 24728 sgd_solver.cpp:46] MultiStep Status: Iteration 2800, step = 3
I0527 16:09:19.209276 24728 sgd_solver.cpp:106] Iteration 2800, lr = 8e-05
I0527 16:09:19.212283 24728 sgd_solver.cpp:143] prelu slope:0.119948 0.091488 0.091623 0.110967 0.091439 0.091635 0.091533 0.091727 0.102938 0.091555 0.091750 0.091561 0.091708 0.091509 0.091710 0.091413 0.091801 0.096627 0.091512 0.091616 
I0527 16:09:19.219302 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000002 0.000010 0.000002 0.000002 0.000002 0.000002 0.000002 0.000003 0.000003 0.000003 0.000002 0.000003 0.000003 0.000002 0.000003 0.000002 0.000002 0.000003 0.000002 0.000002 0.000003 
I0527 16:09:20.427541 24728 solver.cpp:341] Iteration 2875, Testing net (#0)
I0527 16:09:20.465615 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:20.466619 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:20.467622 24728 solver.cpp:410]     Test net output #2: softmax_loss = 7.44528e-05 (* 1 = 7.44528e-05 loss)
I0527 16:09:20.899770 24728 solver.cpp:232] Iteration 2900, loss = 8.3289e-05
I0527 16:09:20.899770 24728 solver.cpp:248]     Train net output #0: softmax_loss = 8.33637e-05 (* 1 = 8.33637e-05 loss)
I0527 16:09:20.906788 24728 sgd_solver.cpp:106] Iteration 2900, lr = 8e-05
I0527 16:09:20.910799 24728 sgd_solver.cpp:143] prelu slope:0.119943 0.091483 0.091618 0.110962 0.091434 0.091630 0.091528 0.091722 0.102933 0.091550 0.091745 0.091556 0.091703 0.091504 0.091705 0.091408 0.091796 0.096622 0.091507 0.091611 
I0527 16:09:20.920825 24728 sgd_solver.cpp:158] weight diff/data(L1):0.000000 0.000001 0.000001 0.000000 0.000000 0.000001 0.000000 0.000001 0.000001 0.000001 0.000000 0.000001 0.000001 0.000000 0.000001 0.000000 0.000000 0.000001 0.000000 0.000000 0.000001 
I0527 16:09:22.523083 24728 solver.cpp:461] Snapshotting to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_3000.caffemodel
I0527 16:09:22.544140 24728 sgd_solver.cpp:319] Snapshotting solver state to binary proto file D:/Research/CNN-based-Indoor-Localization/snapshot/resnet20_iter_3000.solverstate
I0527 16:09:22.560183 24728 solver.cpp:321] Iteration 3000, loss = 6.25418e-05
I0527 16:09:22.560183 24728 solver.cpp:341] Iteration 3000, Testing net (#0)
I0527 16:09:22.607308 24728 solver.cpp:410]     Test net output #0: accuracy_top1 = 1
I0527 16:09:22.607308 24728 solver.cpp:410]     Test net output #1: accuracy_top5 = 1
I0527 16:09:22.608311 24728 solver.cpp:410]     Test net output #2: softmax_loss = 6.4013e-05 (* 1 = 6.4013e-05 loss)
I0527 16:09:22.609314 24728 solver.cpp:326] Optimization Done.
I0527 16:09:22.669473 24728 caffe.cpp:263] Optimization Done.
